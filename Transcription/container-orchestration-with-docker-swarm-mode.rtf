{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1046{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 10.0.17134}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\b\f0\fs36\lang9 Container Orchestration With Docker Swarm Mode\b0\fs22\par
\par
\b\fs32 Course Introduction\b0\fs22\par
\par
Welcome to Container Orchestration with Docker Swarm Mode.\par
\par
About Me\par
I'm Logan Rakai and I'll be your instructor for this Course. I'm a content researcher and developer here at Cloud Academy. I've been thinking a lot about how to maximize the return on your time invested in this course. I'm confident that you'll be confident in your ability to orchestrate containers with Docker Swarm mode after completing the course. I have over ten years of experience in software research and development including five years in the cloud. I'm an AWS Certified DevOps Engineer Professional and a Microsoft Certified Solutions Expert: Cloud Platform and Infrastructure. You can connect with me on LinkedIn or on Twitter.\par
Who this course is for\par
This course is for anyone that is interested in orchestrating distributed systems at any scale.\par
DevOps Engineers\par
Site Reliability Engineers\par
Cloud Engineers\par
Software Engineers\par
\par
Prerequisites\par
In order to get the most out of this course, you should have experience with Docker. You should have a solid understanding of images, networks, volumes, and have experience using Docker compose for managing multi-container applications. If you need to brush up on any of those topics, Cloud Academy has some great courses for that. "Introduction to Docker" by Ben Lambert covers fundamental Docker concepts and "Managing Applications with Docker Compose" by yours truly for working with multi-container applications using Docker Compose.\par
You can follow along with the course examples, and I'd encourage you to. You will need Docker version 1.13 or greater installed. I'll be using a Mac with Docker for Mac version 17.12 installed but you can also follow along in Linux. You should have VirtualBox installed as well. Swarm mode in Windows has some additional limitations mainly around network encryption. I'll mention the limitations when we cover the relevant topic. Almost everything we discuss will apply to Windows environments but I'll be using Linux containers in the demos.\par
I've put resources that I use for the demos on GitHub. A clickable link is available at the bottom of the transcript for this lesson. Most of the work will happen at the command-line although we will work with some files near the end of the course. I'll be using Visual Studio Code for working with the files but you could use whatever you are comfortable with.\par
Learning Objectives\par
After completing this course, you will be able to: \par
" Describe what Docker swarm mode can accomplish\par
" Explain the architecture of a swarm mode cluster\par
" Use the Docker CLI to manage nodes in a swarm mode cluster\par
" Use the Docker CLI to manage services in a swarm mode cluster\par
" Deploy multi-service applications to a swarm using stacks\par
Feedback\par
I'm happy to hear from you. I make content for you and I want it to be as good as it can be. If you have any feedback, please get in touch with me by leaving a comment on the Comments tab below the video, by emailing support@cloudacademy.com, or by connecting with me on Twitter where my handle is @LoganRakai.\par
\par
\par
\b\fs32 Overview\b0\fs22\par
\par
Welcome to this overview lesson on Docker swarm mode. We'll get a conceptual understanding of swarm mode in this lesson before understanding its architecture and diving into the details and demos in following lessons.\par
\par
Agenda\par
We'll start the lesson by getting an understanding of why we need swarm mode. After that, we'll highlight some features of Docker swarm mode to understand what swarm mode can do for you. Next, we'll learn about the main concepts of Docker swarm mode. Lastly, I'll touch on the universal control plane which is Docker's enterprise product built on top of swarm mode.\par
\par
Why Swarm?\par
Docker has made great strides in advancing development and operational agility, portability, and cost savings by leveraging containers. You can see a lot of benefits even when you use a single Docker host. But when container applications reach a certain level of complexity or scale you need to make use of several machines. Container orchestration products and tools allow you to manage multiple container hosts in concert. Docker swarm mode is one such tool.\par
\par
Swarm Mode\par
Swarm mode is a feature built into the Docker Engine providing native container orchestration in Docker. Swarm mode is something you need to enable and when you do, the Docker Engine is said to be running in swarm mode. With swarm mode you can control a cluster of machines in a way that is similar to running and about as easy as running a single Docker Engine. Of course there are some differences and we'll see them in this course.\par
Calling swarm mode a container orchestration feature doesn't quite do it justice. It encompasses cluster management, container orchestration, and more. Some of the main features of swarm mode include:\par
" Integrated cluster management within the Docker Engine without any additional software\par
" A declarative service model that allows you to declare what you want and Docker can create it for you. There is no need for you to specify the sequence of commands to realize what you want.\par
" Swarm mode is able to monitor the cluster state and reconcile any differences between the desired state and the actual state. (Desired state reconciliation)\par
" Swarm mode uses certificates and cryptographic tokens to secure the cluster\par
" As well as features you'd expect in a container orchestration offering such as service scaling, multi-host networking, resource-aware scheduling, load balancing, rolling updates, restart policies, and more.\par
\par
Name disambiguation\par
Docker actually has two cluster management solutions. Both are open source and live on GitHub. Surprisingly, they are both called swarm. Docker Swarm, with a capital S, was the first container orchestration project by Docker. It uses the Docker API to turn a pool of Docker hosts into a single, virtual Docker host using a proxy system. To reduce confusion, Docker Swarm is now referred to as Docker Swarm standalone in documentation.\par
Although Docker Swarm standalone project is still maintained, the newer container orchestration tool is called Swarmkit. It is what is built into the Docker Engine since Docker version 1.12. You might see swarmkit mentioned from time to time, but this is the most commonly referred to as swarm mode. Docker recommends Swarm mode unless you have a specific reason to use Swarm standalone.\par
So now you know that there are two swarms, Swarm standalone and swarm mode. It's useful to be aware of the distinction. You might search for Docker swarm online and stumble upon something related to Swarm standalone when you wanted swarm mode. To avoid any confusion, this course deals exclusively with swarm mode. In the remainder of the course, if I refer to swarm, I'm referring to Docker running in swarm mode. In practice, it's pretty common to drop mode from the name although it can potentially lead to misunderstandings. In the remainder of the lesson, we'll cover the architecture of swarm mode.\par
\par
Swarm Mode Concepts\par
Before going too far, we'll cover some of the main concepts and swarm mode terminology.\par
A swarm consists of one or more Docker Engines running in swarm mode. Each instance of the Docker Engine in the swarm is referred to as a node. It is possible to run multiple nodes on a single machine. For example, by using virtual machines. In production environments, you should use multiple machines to ensure availability of the swarm if a machine goes down.\par
Nodes can participate in a swarm by taking on specific roles: managers and workers. Every swarm requires at least one manager. Managers have several responsibilities, but we'll start simple and consider one main responsibility. Managers accept specifications from users and drive the actual state of the swarm to the specified desired state. They do so by delegating units of work to workers in the swarm. Workers are primarily responsible for running the delegated units of work. Workers also run an agent which reports back to managers on the status of their work. A node can be either a manager, or a worker.\par
The specifications that users submit to managers are called services. This is the same concept as a service in Docker Compose. The service configuration declares its desired state, which includes the networks and volumes it uses, the number of replicas, resource constraints, and other details. A manager will ensure the actual state of the swarm matches the service configuration. if it is possible to realize in the swarm. There may not be enough available resources in the swarm which would prevent the desired state from being achieved. Docker will also make the changes necessary to reconcile the actual state with the desired state if you update a service.\par
There are two kinds of services: replicated and global. You specify the number of replicas for a replicated service based on the scale you desire. A global service allocates one unit of work for each node in the swarm. Global services can be useful for monitoring services, for example.\par
The units of work delegated by managers to realize a service configuration are referred to as tasks. The tasks correspond to running containers that are replicas of the service. Managers schedule the tasks across nodes in the swarm. If a node leaves the swarm, the tasks that the node was running will be scheduled onto the remaining nodes in the swarm.\par
By default, manager nodes also run tasks like workers. You can configure managers to participate exclusively in managing the cluster and that is probably a good idea in production. Allowing managers to run tasks by default enables easy to setup and functional single node swarms.\par
\par
Universal Control Plane\par
The last topic I want to cover in giving an overview of swarm mode is the Universal Control Plane (UCP). UCP is only relevant for the enterprise edition of Docker so I will only briefly touch on it.\par
Working with swarm mode is similar to working with Docker. You interact with it through the Docker CLI. That is great, but sometimes it can be nice to have a web interface to manage and visualize the cluster and containers. UCP is Docker's enterprise offering that is built on top of swarm mode to provide a web interface for cluster management and role-based access control. Because UCP is built on swarm, what you learn in this course applies to UCP as well.\par
\par
Closing\par
All right, now we have a basic understanding of swarm mode. We will take closer look at how swarm mode works by understanding main components of its architecture in the next group of lessons.\par
\par
\par
\b\fs32 Networking\b0\fs22\par
\par
Thanks for joining me for this lesson on Docker swarm mode architecture. You heard about the great benefits swarm mode provides in the previous lesson. In these architecture lessons, we'll understand more about the parts of swarm mode that enable it to accomplish all those great benefits, starting with networking. This lesson and the following architecture lessons build the foundations for using swarm mode. I promise we'll be seeing swarm mode in action in the demos of the next lesson group in the course.\par
\par
Agenda\par
This lesson will cover everything that is unique to swarm mode and networking:\par
" (Overlay networks) Starting with a Docker network type exclusive to swarm mode, the overlay network. \par
" (Service discovery) After that, we'll discuss how services in a swarm can be discovered across multiple host swarm networks. \par
" (Load balancing) On a related note, we'll see how load is balanced across all the replicas of a service. \par
" (External access) Then the mechanisms for accessing the swarm services from outside the swarm will be explored.\par
\par
Networking\par
The networking requirements in a swarm are much more complex than using a single Docker host. Services need to communicate with one another and the replicas of the service can be spread across multiple nodes. Fortunately, Docker includes a network driver that makes multi-host networking reliable, secure, and a breeze to set up.\par
\par
Overlay Networks\par
The driver I'm referring to is the overlay network driver. With the overlay driver a multi-host networking in a swarm is natively supported. There is no need to perform any external configuration. You can attach a service to one or more overlay networks, in the same way you would attach a container to one or more user-defined networks when not running in swarm mode. \par
Overlay networks only apply to swarm services and can't be connected to by containers that aren't part of a swarm service. Managers automatically extend overlay networks to nodes that run tasks requiring access to a given overlay network.\par
\par
Network isolation and firewalls\par
It's a good time to review Docker network isolation and firewall rules. These rules apply to overlay networks just as they do for bridge networks.\par
Containers within a Docker network are permitted access on all ports of containers in the same network.\par
Access is denied between containers that don't share a common network.\par
Traffic originating inside of a Docker network and not destined for a Docker host is permitted. For example, access to the internet. However, any network infrastructure outside of Docker may still deny the traffic.\par
Ingress traffic, or traffic coming into a Docker network, is denied by default. Ports must be published in order to grant access form outside of Docker.\par
\par
Service Discovery\par
With services distributed across multiple nodes, a service discovery mechanism is required in order to connect to the nodes running tasks for a service. Swarm mode has an integrated service discovery. It is based upon the domain name system (DNS). The DNS is internal to Docker and implemented in the Docker Engine. It is used for resolving names to IP addresses.\par
Actually, the same service discovery system is used when not running in swarm mode. Service discovery in Docker is scoped to a network. When you are in swarm mode, the network can be an overlay spanning multiple hosts. But the same internal DNS system is used. All nodes in a network store corresponding DNS records for the network. Only service replicas in the network can resolve other services and replicas in the network by name.\par
\par
Internal Load balancing\par
There are some unique service discovery considerations for Swarm mode. Each individual task is discoverable with a name to IP mapping in the internal DNS. But because services can be replicated across multiple nodes, which IP address should a service name request resolve to? Docker assigns a service a single virtual IP (VIP) address, by default. Requests for the virtual IP address are automatically load balanced across all healthy tasks spread across the overlay network. By using a virtual IP, Docker can manage the load balancing allowing clients to interact with a single IP address without considering load balancing. It also makes the service more resilient since the service can scale and tasks can change the nodes that they are scheduled on but clients are sheltered from the changes.\par
\par
Internal load balancing example\par
To illustrate how service discover and load balancing work in swarm mode, consider two services deployed in a swarm service A and service B. Service A has a single replica while service B has two replicas. When service A makes a request for service B by name, the virtual IP of service B is resolved by the DNS server. Service A uses the virtual IP to make a request for service B. Using support for ip virtual servers (IPVS) the request for the virtual IP address is routed to one of the two nodes running service B tasks.\par
\par
DNS Round Robin\par
Besides the default virtual IP, you can configure load balancing using DNS round robin (DNS RR). You can configure the load balancing on a per service basis. When DNS round robin is used, the Docker Engine's DNS server resolves a service name to individual task IP addresses by cycling through the list of IP addresses of node's running a task in the service. If you need more control over load balancing than a virtual IP can give you, DNS round robin should be used for integrating your own external load balancer.\par
\par
External Access\par
We've covered access to services within a Docker network, but what about accessing a service from the outside? With a single Docker host, you would publish a container port on the host to permit access to a container. Similar functionality is still available in swarm. But there are actually two modes for publishing ports in swarm.\par
\par
Host mode\par
The first is the same as you would expect when publishing a port when not running in swarm mode. The container port is published on the host that is running the task for a service. This mode is referred to as host mode service publishing. You need to be careful with specifying a host port in host mode. If you have more tasks than available hosts, tasks will fail to run because the host port can only be bound to one task. You can omit a host port to allow Docker to assign an available port number in the default port range of 30000-23767. However, this can make it more difficult to work. Also, there isn't load balancing unless you configure it externally. Obviously, that is useful when you don't want load balancing, but what about when you do?\par
\par
Ingress mode\par
Because services can be replicated and tasks can be rescheduled onto different nodes as the state of the swarm changes, it is useful to have the option to load balance a published port across all tasks of a service. This is referred to as ingress mode service publishing. For convenience, all nodes in the swarm publish the port. This is different from host mode where a port is only published if the node is running a task for the service. In ingress mode, requests are round robin load balanced across the healthy instances of the service's tasks regardless of the node that receives the request.\par
Ingress mode is the default service publishing mode. It's ideal when you have multiple replicas of a service and need to load balance between them. Host mode publishing is useful when you have an external service discovery service and potentially for global services where one task for a service runs on each node. For example, a global service that monitors each node's health shouldn't be load balanced since you want to get the status of a specific node.\par
\par
\par
Routing Mesh\par
At this point, you might be wondering how ingress mode publishing work. The magic happens in what is called the routing mesh. The routing mesh combines two of the swarm components that we discussed earlier: an overlay network, and a service virtual IP.\par
When you initialize a swarm, the manager creates an overlay network named ingress. Every node that joins the swarm is in the ingress network. The sole purpose of the ingress network is to transport traffic from external clients that is destined to published service ports to the service inside the swarm.\par
When a node receives an external request on the ingress network the node resolves the service name to a virtual IP address. This process is carried out using the same internal DNS server as we discussed in the internal load balancing. The IP virtual server then load balances the request to a service replica over the ingress network.\par
Because every node is in the ingress network, every node can resolve the external requests can handle the external requests. The nodes need to have a couple of ports open for all of this magic to work:\par
o Port 7946 for both TCP and UDP protocols to enable container network discovery.\par
o Port 4789 for the UDP protocol to enable the container ingress network.\par
It's worth mentioning that you could add an external load balancer on top of the load balancing provided by the routing mesh. For example, if you have nodes running in the cloud, you can have the nodes in a private subnet so they aren't directly accessible from the internet. You could provision a cloud load balancer to handle requests from the internet and load balance them across nodes in the swarm. The swarm nodes then load balance again across the nodes running tasks for the service.\par
As a final note on the routing mesh, if you are planning to use the routing mesh on Windows, you need to be running version 17.09 or greater.\par
\par
docker_gwbridge\par
Besides the ingress network, Docker also creates a second network when running in swarm mode called docker_gwbridge. The docker_gwbridge is a virtual bridge that connects the overlay networks (including the ingress network) to an individual Docker daemon's physical network. This interface provides default gateway functionality for all containers attached to the network. Docker creates it automatically when you initialize a swarm or join a Docker host to a swarm, but it is not a Docker device. It exists in the kernel of the Docker host. You can see it if you list the network interfaces on your host.\par
\par
Recap\par
There was quite a few topics related to networking in swarm mode. Let's recap the main points:\par
" Swarm mode includes a new type of Docker network, the overlay network. Overlay networks make it easy to use multi-host networking in a swarm.\par
" The same internal DNS service discovery mechanism used when not running in swarm mode is used in swarm mode. The internal DNS naturally extends to multi-host networks.\par
" The services in a swarm can be load balanced by using a virtual IP address or by DNS round robin.\par
" External access to the swarm is made possible by publishing ports. There are two modes for publishing in swarm mode: host and ingress. \par
o In host mode each service replica publishes it's container port on the host. No load balancing is used. \par
o In ingress mode, every node in the swarm publishes the port and requests are load balanced across all the replicas of a service. Any node can handle requests for the service even if the node doesn't have a replica of the service itself. \par
" Ingress mode is made possible by the swarm routing mesh which uses two default swarm networks: the ingress overlay network and docker_gwbridge network\par
\par
Closing\par
In the next lesson, we'll look into swarm mode container orchestration features including rolling updates and scheduling constraints. When you're ready continue on to the next lesson to see how swarm can orchestrate containers.\par
\par
\par
\b\fs32 Orchestration\b0\fs22\par
\par
Swarm mode is made to be familiar to single host Docker users. When you deploy a service, it is similar to running a container. You can specify an image, volumes, networks, published ports, After all, service tasks ultimately run containers. But there are container orchestration features of swarm mode that are unique to running services in a swarm.\par
Agenda\par
We'll look at the following orchestration features of swarm mode:\par
" (Service placement) Which nodes service tasks are placed on\par
" (Update behavior) how service updates are rolled out, and\par
" (Rollback behavior) how services can be rolled back to a previous version.\par
\par
Service placement\par
As we've discussed, services can declare a set number of replicas as a replicated service or can be started on every worker node in a cluster as a global service. For replicated services, decisions need to be made by swarm managers for where service tasks will be scheduled, or where the service will be placed. A replicated service's tasks will be spread across nodes by default. That is to promote high availability in case a node fails. But there are three ways that you can influence where a service is placed:\par
1. CPU and Memory reservations\par
2. Placement constraints\par
3. Placement preferences\par
You can specify each at service creation time. Global services can also be restricted to a subset of nodes with these conditions. Although a node will never have more than one task for a global service. Let's take a closer look at each.\par
\par
CPU and Memory reservations\par
Similar to running individual containers, you can declare CPU and memory reservations for services. Each service task can only be scheduled on a node that has enough available CPU and memory to meet the given reservations. Any tasks that remain stay in a pending state until a node with sufficient resources becomes available. Global services will only run on nodes that meet a given resource reservation.\par
Setting sufficient memory reservations for services is important when there isn't an abundance of CPU and memory available for the applications you are running. If services attempt to use more memory than is available, the container or Docker daemon could get killed by the out of memory or OOM killer.\par
\par
Placement constraints\par
Placement constraints allow you to restrict the placement of tasks by providing equality and inequality conditions. The conditions compare node attributes to a string value. There are a few built-in attributes for each node\par
1. node.id matches the ID of a node\par
2. node.hostname matches a node's hostname\par
3. node.role matches a node's role, either manager or worker\par
You can also define your own labels. You can configure labels on a Docker engine or on a node. Engine labels are usually used to indicate things like operating system, system architecture, available drivers. An example is engine.labels.operatingsystem and values could be Ubuntu 14.04 or Windows Server 2016. Node labels are added by Swarm administrators for operational purposes. Node labels can indicate they type of application a node is intended to run, the datacenter location a node is in, the server rack a node is in, et cetera. An example is node.labels.datacenter and values could be north, south, east, or west.\par
When you provide multiple placement constraints for a service, all constraints must be satisfied by a node in order to be scheduled a service task. If resource reservations are also provided, all constraints and resource reservations must be met. This is true for replicated and global services.\par
\par
Placement Preference\par
Placement preference is not required as was the case for resource reservations and placement constraints. Instead, placement preferences influence how tasks are distributed across appropriate nodes. Currently the only distribution option is spread which will evenly spread tasks. \par
Labels are again used as the attribute for spreading tasks. For example, assume every node in a swarm has a datacenter label with either east or west as the value. Using the datacenter label and the spread placement preference, half of the tasks will be scheduled on east datacenter nodes and the other half on west datacenter nodes.\par
Multiple placement preferences can be specified. In this case a hierarchy of preferences is created. For example, if the first preference is datacenter and the second Is server-rack, tasks will be evenly spread across nodes in each datacenter, and within each datacenter tasks are spread evenly across racks.\par
Nodes that are missing a placement preference label are included in the spread and receive tasks in proportion equal to all other label values. They are treated as the group having the null value for the label. Placement preferences are ignored by global services.\par
That's all that there is to influencing service placement in swarm.\par
\par
Update Behavior\par
You can also configure the way that swarm applies updates to services. Swarm supports rolling updates where a fixed number of replicas are updated at a time until all service replicas have been updated.\par
You can configure several update parameters:\par
1. Update parallelism, which sets the number of tasks the scheduler updates at a time\par
2. Update delay, which sets the amount of time between updating sets of tasks, and \par
3. Update failure action, which can be set to pause, continue or automatically rollback if an update fails. The default is to pause.\par
These are the three main settings. There are also settings to configure what qualifies as failure. You can set a ratio for the number of failed task updates to tolerate before failing a service update, and set the frequency for monitoring for a failure.\par
These parameters give you some flexibility in how aggressively or conservatively you roll out an update to the swarm.\par
\par
Rolling Back Updates\par
Docker swarm keeps track of the previous configuration for services. This allows you to rollback manually at any time or automatically when an update fails, as we discussed.\par
The same options available for configuring update behavior are available separately for configuring rollbacks. For example, rollback parallelism sets how many nodes to roll back at a time.\par
\par
Recap\par
In this lesson, we saw how you can influence the nodes that swarm schedules services on by using resource reservations, placement constraints, and placement preferences. Resource reservations and placement constraints must be satisfied, while placement preferences won't prevent a task from being scheduled. We also discussed how rolling updates and rollbacks can be configured in Swarm. Updates and rollbacks share the same available configuration options.\par
\par
Closing\par
In the next lesson, we'll see how swarm mode keeps a consistent view of the swarm. An important topic for any distributed system. When you are ready, continue on to the next lesson to learn about swarm mode consistency.\par
\par
\par
\b\fs32 Consistency\b0\fs22\par
\par
Consistency is an important consideration for any distributed system. In this lesson, we'll look at the consistency model of swarm mode and how it can impact how you operate a swarm.\par
Agenda\par
To kick things off we'll discuss:\par
" (Consistency) the consistency problem and \par
" (Raft) how swarm mode goes about solving it, in particular the Raft Consensus algorithm. \par
" (Tradeoffs) We'll cover just what you need to know of Raft to understand key tradeoffs that you should consider when deciding on the composition of your swarm.\par
" (Raft Logs) Lastly, we'll talk about the raft logs where the cluster state is stored.\par
\par
Consistency\par
We have seen that swarm mode can include several manager and worker nodes in a swarm. This provides fault tolerance if a node were to go down and ensures services are highly available. But with multiple managers, how does swarm make decisions regarding the state of the cluster? Do nodes in the swarm share a consistent view of the cluster or could one node have a different view than the other? And if so, for how long? These questions all touch on the issue of consistency.\par
In swarm mode, managers all share a consistent internal state of the entire swarm. This avoids any potential issues that could arise if managers were allowed to eventually converge to a shared state. Workers, on the other hand, do not share a view of the entire swarm. That is exclusively a manager responsibility.\par
The managers maintain a consistent view of the state of the cluster by using a consensus algorithm. There are several consensus algorithms to choose from and the implementation details are outside the scope of this course. But the consensus algorithm has an impact on how the swarm operates. We'll look at the basics of swarm modes consensus algorithm so we can understand the implications in operating a swarm.\par
\par
Raft Consensus\par
The consensus algorithm used by managers to maintain a consistent view of the state of the cluster is called Raft. Raft achieves consensus by electing one manager as the leader. The elected leader makes all of the decisions for changing the state of the cluster to bring it to the desired state. For example, the leader accepts new service requests and service updates and also decides how to schedule tasks.\par
In order to maintain a consistent view across the managers, the decisions aren't acted upon until a majority of managers agree on the proposed changes to the cluster. A manager "agrees" simply by receiving a proposed change and acknowledging they received it. When the leader is certain a majority of managers have received the proposed change, the change can be implemented. In this context, the majority of managers are referred to as a quorum.\par
The reason why a quorum is enough to proceed is because Raft limits how many managers failures it can tolerate. If you have N managers in a swarm, Raft allows for (N-1)/2 failures. In the case of a three manager swarm, that means 3 minus 1 divided by two is one, so one manager can fail and the swarm can continue to operate as usual. If two managers were to fail, the cluster state would freeze until a quorum of managers again became available. In the absence of a quorum, currently running services will continue to run but no new scheduling decisions take place.\par
Regarding leader elections, when a swarm is initialized the first manager is automatically the leader. If the currently elected leader fails or voluntarily steps down, say to perform system updates, an election between remaining manager nodes takes place. Until a newly elected leader is chosen, the cluster state is frozen.\par
\par
Manager Tradeoffs\par
After that overview of Raft consensus, you might be tempted to add a lot of managers to your swarm. The more managers, the more failures your swarm can tolerate and remain fully operational. Although, that is true, the more managers that are in the swarm also increases the amount of managerial traffic required for maintaining a consistent view of the cluster and the amount of time it takes to achieve reach consensus with every state change. Although increasing managers does increase fault-tolerance it generally decreases performance and scalability.\par
There are some general rules for setting the number of managers:\par
You should usually have an odd number of managers. Having an even number of managers doesn't improve the fault tolerance compared to having one less manager and increases communication overhead. \par
A single manager swarm is acceptable for development and test swarms. Because a single manager swarm can't tolerate any failures, it is not something you should use in production.\par
A three manager swarm can tolerate one failure, while a five manager swarm can tolerate two.\par
Docker recommends a maximum of seven managers which can tolerate three manager failures. Above seven has too much of an impact on performance to be beneficial.\par
However many managers you settle on, you will want to distribute them across availability zones to maintain a fully operational swarm in the event of a datacenter outage. Docker recommends distributing across at least three availability zones in production.\par
\par
Working Manager\par
There is another tradeoff when considering managers in a swarm. Have you heard the bad joke that goes "Don't stand around doing nothing. People will think you're the boss." In swarm mode, you need to consider whether or not you let the boss, or the managers, do work. By default managers perform worker responsibilities, namely running tasks. But that has more to do with enabling single node swarms than anything.\par
Because managers participate in the Raft consensus process, it can be detrimental to the performance of the swarm if managers are overly utilized. You can use conservative resource reservations to make sure that managers won't become starved for resources. To be on the safe side, you can also prevent any work from being scheduled on manager nodes by draining them. Draining essentially removes any tasks currently on a node and preventing new tasks from being scheduled to it.\par
\par
Worker Node Tradeoffs?\par
You might be wondering if there are any tradeoffs to consider when adding worker nodes to a swarm. There really isn't much to worry about in the case of adding more worker nodes. More workers give you more capacity for running services and improves service fault tolerance. More workers don't affect the manager's raft consensus process so the swarm performance isn't harmed.\par
Workers actually do participate in a consensus process. To exchange overlay network information nodes participate in a weakly-consistent, highly scalable gossip protocol called SWIM. The details are outside the scope of this course and the performance implications are negligible. The protocol is an example of an eventually consistent model where the network state is allowed to differ between nodes but eventually they converge on a consistent view.\par
\par
Raft logs\par
The last topic we'll discuss in this lesson is Raft logs. If you arrived at this lesson from a search for log rafts, I'm afraid you'll need to continue your search. The logs we're talking about are where the leader manager records the Raft consensus state changes, such as creating a new service or adding a new worker. These logs are what get shared with other managers to establish a quorum.\par
The Raft logs are persisted to disk. The logs are stored in the raft subdirectory of your Docker swarm data directory. This is /var/lib/docker/swarm on Linux by default. As part of a disaster recovery strategy, you can back up a swarm cluster by backing up the entire swarm directory which includes certificates and other files in addition to the raft change logs in the raft subdirectory. You can restore a new swarm from a backup by replacing the directory swarm directory with the backed-up copy.\par
\par
Recap\par
That's everything for this lesson. We started by understanding how swarm mode solves consistency challenges by electing a leader manager and ensuring a majority of managers acknowledge swarm changes. This strategy comes from the Raft consensus algorithm. We understood the tradeoffs between fault tolerance and performance when choosing the number of managers in a swarm, as well as whether or not managers should do work. We finished by discussing the raft logs which are persisted on disk and record all the changes the leader makes to a swarm.\par
\par
Closing\par
In the next lesson, we will cover the security measures included in swarm mode. Continue on to the next lesson when you are ready to learn about security in Docker swarm mode.\par
\par
\par
\b\fs32 Security\b0\fs22\par
\par
Docker takes security seriously. All the security features that you can use when not running in swarm mode can be used in swarm mode. This includes using trusted images, encrypted communication with docker engines, and kernel security features leveraged by Docker. This lesson covers the security provisions in Docker swarm mode.\par
Agenda\par
We'll begin by covering the \par
" (Cluster Management) cluster management aspects of swarm security\par
" (Data Plane) Next, we will discuss security of data communicated between services\par
" (Secrets) After that, we'll see how swarm secrets are kept secure.\par
" (Locking a Swarm) Lastly, the locking functionality of a swarm will be described.\par
\par
Cluster Management\par
Docker swarm mode uses public key infrastructure (PKI) to secure swarm communication and state. Swarm nodes encrypt all control plane communication using mutual transport level security (TLS). When you initialize a swarm, Docker assigns the node that executed the command as a manager. The manager automatically creates several resources for security:\par
" A root Certificate Authority (CA): This plays the standard role of a CA in PKI by being a trusted entity that issues certificates verifying the identity of certificate holders.\par
" A key pair: This is the public and private key used for secure communication between nodes in the swarm.\par
" A worker token: This token is used to by nodes to join the swarm as a worker node. The token is a digest of the root CA and a secret.\par
" A manager token: This is similar to the worker token but used to join nodes as managers in the swarm.\par
Whenever a new node joins the swarm, the manager issues a new certificate identifying the node. The node uses the certificate for communicating in the swarm. New manager nodes also get a copy of the root CA certificate so that they can take over leadership in the event of an election.\par
You can use an alternate CA instead of allowing Docker to automatically handle their creation for you. The CA can also be rotated out whenever your security policies require it. Rotating the CA will automatically rotate the TLS certificates of all swarm nodes in the cluster.\par
\par
Data Plane\par
As for the data plane, you can enable encryption of overlay networks at the time of creation. Any time traffic leaves a host an IPSec encrypted channel is used to communicate with a destination host where the traffic is decrypted. The swarm leader periodically regenerates and distributes the key used for encrypting IPSec data plane traffic. Overlay network encryption is not supported for Windows as of Docker version 17.12.\par
\par
Raft Logs/Secrets\par
The Raft logs are encrypted at rest on the manger nodes. This protects against intruders that gain access to the raft logs on disk. The encryption is particularly important because swarm secrets are stored in the raft logs. Secrets are a feature of swarm that allows you to securely store secrets that can be used by services. This could include passwords, API keys, or any other information you wouldn't want to be exposed over the network or in a Dockerfile. In Windows, secrets are supported in version 17.06 an above.\par
\par
Locking a Swarm\par
A challenge with encrypting the raft logs is that the keys used to encrypt the logs needs to be stored somewhere a manager has access to. By default, the keys are stored on disk along with the raft logs. If an attacker gains access to the raft logs, there is a good chance they could gain access to the keys used to encrypt them. They could then decrypt the logs and expose any secrets therein.\par
For an extra layer of security, a swarm allows you to take control of the key used for encrypting the logs. This allows you to implement strategies where the key is never persisted to disk. This works with a swarm feature called autolock. When a swarm is autolocked, you must provide the key when starting a docker daemon. For greatly improved security, you have to pay that price of requiring manual intervention when a manager is restarted. You can rotate the key at any point or disable autolock so managers can be restarted without intervention.\par
\par
Recap\par
In this lesson, we saw the security measures that are in place in out of the box when using swarm mode. This included several security layers with regards to managing a cluster. We also saw how overlay network communication can optionally be encrypted to secure communication between services. Swarm supports sharing secrets and uses encryption to protect the secrets on disk in the manager Raft logs. The keys for decrypting the logs are stored on disk by default, but you can use autolocking to take control of the keys and improve the defense of your swarm.\par
\par
Closing\par
We have now covered all of the architecture topics related to swarm mode. In the following lesson group, we will get hands-on with a swarm and see how to operate and use a swarm from the command line and by describing applications in stack files.\par
\par
\par
\b\fs32 Setting Up a Swarm\par
\b0\fs22\par
All right, this lesson and remaining lessons focus more on getting hands-on with Docker swarm mode. You will see a lot of the concept knowledge that you've built up in the previous lessons in action. These lessons will focus more on the commands you need to use to accomplish tasks related to swarm mode, starting with setting up a swarm.\par
Agenda\par
We will begin by laying out the options available to you for setting up a swarm mode cluster. After that we'll show two ways to set up a swarm locally on your machine: as a single node swarm and as a multi-node swarm using virtual machines.\par
Options for Creating a Swarm\par
There are several options for creating a swarm mode cluster. You should consider factors such as the workloads you want to deploy on the swarm, the management complexity, and cost when determining which option to choose.\par
The simplest option is creating a single-node swarm. Recall that swarm mode managers can also perform work by default meaning that you can run swarm workloads with a single node. We will see later in this lesson how easy it is to set up. This may be appropriate in development and test scenarios. With no fault tolerance, it is not something to do in production.\par
The other options are for multi-node clusters. There are unmanaged options that you put you in charge of maintaining the infrastructure and applying patches, and there are more managed options where you can use the swarm as a service without worrying about hardware or software patches.\par
For the unmanaged option, you would likely have your own compute cluster or private cloud. You would need to ensure Docker is installed on the bare metal servers or on virtual machines running on top. The network firewall would need to allow traffic on the ports swarm mode requires (TCP port 7946 and UDP ports 7946 and 4789). The Universal Control Plane that is available through Docker Enterprise edition can set up an on-prem swarm using a graphical interface.\par
Here is a screenshot of the UCP web interface in action showing a three node swarm.\par
We will setup a multi-node cluster using VMs on a single physical host later in this lesson. You could run VMs in a public cloud and make a swarm out of the VMs. However, there may be a better option if you are going to leverage the public cloud.\par
For the more managed options, you could use cloud provider templates that allow you to set a few parameters and have swarm created for you. This is true for Microsoft Azure, Amazon Web Services, and IBM Cloud. You can also leverage Docker's Docker Cloud offering to create swarms on Azure and AWS through the Docker Cloud graphical interface. Each option is explained in Docker's own documentation.\par
\par
Demo\par
Now, it's time to demo setting up some swarms. I'll first setup a single node swarm and then a multi-node swarm using virtual machines and the help of the docker-machine command.\par
\par
Single Node Swarm\par
I'm here at my terminal on my mac. I have Docker for Mac installed\par
$ docker version\par
To see the current status of the Docker daemon's swarm mode, you can use the docker info command and look for the Swarm key:\par
$ docker info | grep Swarm\par
The inactive value means the daemon is not running in swarm mode.\par
Now we'll see how easy it is to start running in swarm mode. The commands relevant to managing a swarm are under the swarm subcommand of the Docker CLI.\par
$ docker swarm --help\par
In the commands list you see everything from rotating the root certificate authority for a swarm to unlocking a locked swarm. The only command needed to start a new swarm is \par
$ docker swarm init\par
And that's all that it takes to start running a single-host swarm. The output tells you that the current node is running as a swarm manager and provides a command for joining workers to the swarm. The value of the token argument is the worker join token. A similar looking token is used for joining manager's to a swarm as seen from the join-token manager output\par
$ docker swarm join-token manager\par
Let's probe around to see some of the changes that occur when you start running in swarm mode. First, let's revisit the docker info output\par
$ docker info\par
The state has changed to active to indicate that the daemon is indeed running in swarm mode. There is also a bunch of useful tidbits related to the swarm's configuration: Number of managers, number of nodes, right down to internals of the Raft consensus algorithm. You can even eek out additional information including TLS certificate info by using the format flag and specifying the Swarm field\par
$ docker info --format '\{\{json .Swarm\}\}'\par
I'll clear that because it is quite unsightly and there is no pretty print option.\par
We can also verify that the networks we learned in the swarm architecture lessons have been created\par
$ docker network ls\par
Here we see the docker_gwbridge local bridge network for connecting overlay networks to the hosts network and the ingress network used for handling external ingress traffic to the swarm.\par
That's all there is to the single-node swarm. You could start using it for development and test scenarios as is. For demonstration purposes, I want to use a multi-node cluster so I will tear down our current swarm. To do that, you force leave the swarm\par
docker swarm leave --force\par
The force flag is required because when the last manager in a swarm leaves all the swarm state goes with it. This is what we want to happen in this case.\par
I'll set up a multi-node swarm with two workers and one manager for demonstrating various swarm concepts. Remember that one manager is not a good idea in production, but it is going to be enough to illustrate working with a swarm mode cluster. To quickly create Docker-enabled VMs, I'm going to use docker-machine. \par
$docker-machine\par
docker-machine comes installed with Docker for Mac and Docker for Windows. Only a few docker-machine commands are needed so I'll explain them as they are required. But know that there is a lot more to docker-machine than what I'll explain in this lesson.\par
\par
The first command is create, which does exactly what you'd expect. \par
$ docker-machine create vm1\par
By default it will create a VM in VirtualBox using an image with docker installed. Virtualbox was installed previously on my mac so everything went off without a hitch. I'm using the names vm1, vm2, and vm3 instead of more descriptive names like manger1 because it's possible for nodes to change their role in a swarm. However, vm1 will be used as the manager in this lesson. I'll speed this up until it finishes\'85\par
Now I'll create vm2 in the same way\par
$ docker-machine create vm2\par
And finally vm3\par
$ docker-machine create vm3\par
Now I'll use the ls command to list the vms and their IP addresses\par
$ docker-machine ls\par
The machines are at 192.168.99.100, 101, and 102. The VMs are running the 18.01 edge release which doesn't have any significant changes in swarm mode compared to the 17.12 stable release I have running on my Mac. I'll connect to vm1 using docker-machine's ssh command\par
$ docker-machine ssh vm1\par
And I'll show docker info to confirm that docker is installed but swarm mode is inactive\par
$ docker info\par
To initialize a swarm, I'll use the same init command as with a single-node setup but with an advertise address:\par
$ docker swarm init --help\par
The advertise address is the IP address other nodes will use to join the swarm.\par
$ docker swarm init --advertise-addr 192.168.99.100\par
I'll give the IP address but you could alternatively provide the network interface name. I'll copy the prepared join command for joining workers. You can always retrieve the join token later using the join-token swarm subcommand. \par
I'll drop out of vm1 and ssh into vm2 to join the swarm\par
$ exit\par
$ docker-machine ssh vm2\par
$ docker swarm join \'85\par
The output acknowledges that the node joined the swarm as a worker node. Now I'll repeat the process for vm3.\par
To confirm the swarm has one manager and 3 nodes in total, I need to run the docker info command on the manager node, which is vm1. \par
$ docker info\par
There we have it, a 3-node swarm with one manager setup with the help of docker-machine.\par
\par
Recap\par
In this lesson, we learned some of the options available for setting up a swarm mode cluster. These included some high touch options putting you in charge of the hardware and software patching to fully automated solutions like the one provided by Docker Cloud allowing you to spin up a swarm on Amazon Web Services or Azure from the comfort of a graphical interface. \par
We then saw how to set up a single node swarm using the swarm init command\par
After we set up a multi-node swarm with the help of docker-machine and Virtualbox. The same init command was used with an advertise address for other nodes to use to join the swarm using the join command.\par
This is a depiction of the swarm that we currently have set up. vm1, vm2, and vm3 are all in the swarm, while my mac is not participating in the swarm. vm1 is the swarm manager, as indicated by the orange tie. We'll use this multi-node swarm for the remainder of the lessons.\par
Closing \par
In the next lesson, we'll see how to manage nodes in a swarm. When you are ready, continue on to the next lesson.\par
\par
\par
\b\fs32 Managing Nodes\b0\fs22\par
\par
We now have a 3-node swarm with one manager. This lesson will demonstrate how to perform swarm node management tasks. For example, promoting a worker to a manager, organizing nodes with labels, and preventing manager's from doing work.\par
Agenda\par
I'll give a brief overview of the swarm node management tasks we'll be going through. We'll spend most of the time at the command-line where we'll execute the tasks on the swarm we stood up.\par
\par
Node Management\par
Promoting\par
The first task that we'll go through is promoting a worker node to a manager. You may want to do this to increase your fault-tolerance or in order to take an existing manager out of service without impacting the number of managers available. Remember that if you are going for an increase in fault-tolerance that you should increase the manager count up to the next odd number. For example, going from one manager to three.\par
\par
Demoting\par
Demoting is the opposite of promoting. It takes a node that is currently in a manager role and demotes the node to a worker role.\par
\par
Availability\par
The availability of a node refers to the ability to schedule tasks to the node. It isn't whether a node is up or down which one might logically guess. The availability of a node is configured by managers. The allowed availability states are: active, pause, and drain. Active means that work can be scheduled on a node, pause means no new work can be scheduled but existing work scheduled on the node won't be canceled, and drain means nothing can be scheduled and any running work is terminated. Setting availability to drain is useful for gracefully taking a node offline to perform maintenance. Draining managers is also useful to prevent them from having work scheduled to them, which is the default behavior.\par
\par
Labeling\par
The final node management task that we'll demonstrate is labeling. Recall that labels are useful for influencing where services are placed in a swarm. For example, labels can be used to ensure that tasks are scheduled in different availability zones to provide service availability SLAs.\par
\par
Demo\par
Now I'll hop over to the command-line and start with the demo\par
I'm connected into the vm1 swarm node which is currently the manager of the swarm. In docker, node management tasks are accomplished by using the docker node management command. \par
$ docker node --help\par
There are some standard commands that are available for most docker management commands: namely ls for listing nodes, ps for listing tasks scheduled to nodes, and rm for removing nodes from a swarm. Inspect is also a familiar docker command that lists detailed information about a node. To get a view of the swarm, I'll run the ls command\par
$ docker node ls\par
And we see the three nodes, that all three are available, and that only vm1 is a manager, and is therefore the leader.\par
\par
To promote vm2 to the manager role in the swarm, I'll use the promote command:\par
$ docker node promote vm2\par
And easy as that vm2 is now a manager in the cluster\par
$ docker node ls\par
The manager status of reachable means the node is a manager and is participating in the Raft consensus quorum. The other possible manager status is unavailable, which indicates the manager has a problem communicating with the other managers.\par
\par
To change vm2 back to the worker role, I'll use the demote command:\par
$ docker node demote vm2\par
$ docker node ls\par
\par
Next up is modifying the availability of a node. You can use the update command for that\par
$ docker node update --help\par
The availability option does what we want. You can also see the label-add and label-rm options which add and remove labels from nodes. There's also the role option which promote and demote are a short form of updating a node to the role of either worker or manager. Let's say we don't want the manager to have any tasks scheduled to it, so I'll set the availability of vm1 to drain\par
$ docker node update --availability drain vm1\par
$ docker node ls\par
and the availability in the ls table reflects the change.\par
\par
I actually want the manager to be able run tasks so I'll undo that by setting availability to active\par
$ docker node update --availability active vm1\par
\par
To finish up I'll add a fictitious availability zone labels to each node using the label-add update option. I'll say vm1 is in zone 1, vm2 is in zone 2, and vm3 is in zone 3:\par
$ docker node update --label-add zone=1 vm1\par
$ docker node update --label-add zone=2 vm2\par
$ docker node update --label-add zone=3 vm3\par
To see node labels, you need to use the inspect command\par
$ docker node inspect vm3\par
Here is the labels property in the Spec. You can also filter out everything but the labels by using the format option with a Go template\par
$ docker node inspect -f '\{\{.Spec.Labels\}\}' vm3 \par
Here again is the zone label key-value pair in the Labels map.\par
\par
Recap\par
In this lesson we learned about the node management tasks that are part of managing a swarm. We understood the concepts and demonstrated how to promote and demote a node, set a node's availability, and label swarm nodes.\par
This slide shows the current state of our swarm. Each node is now labeled with a zone compared to where we began the lesson.\par
\par
Closing\par
In the next lesson, we'll see how to schedule tasks onto the swarm by using services. If you are ready to see swarm mode in action, continue on to the next Lesson.\par
\par
\par
\b\fs32 Managing Services\b0\fs22\par
\par
Services are what make up distributed applications running on a swarm. In this lesson, we'll get experience running and managing services in our swarm.\par
Agenda\par
To begin, I'll give a quick rundown of what services we'll be running, and then we'll get into the demo.\par
\par
The Plan\par
I'll use two images for demonstrating how to work with services. \par
The first is a swarm visualizer provided by Docker. It allows you to visualize the state of nodes in a swarm and see where service tasks have been scheduled. It requires information that only manager nodes have access to. We'll constrain the placement of the service to make sure it gets what it needs.\par
The second is a web service that serves a simple web page that displays the name of the node running the task. This will give us a way to verify that requests are load balanced across multiple nodes when using the ingress network in swarm.\par
\par
Demo\par
Ok, now let's get to the demo.\par
When working with services, all of the commands are conveniently located under the docker service management command\par
$ docker service --help\par
There are some familiar commands: inspect, logs, ls, ps, and rm. They do what you would expect given your knowledge of the Docker CLI. We'll use them as we work through this demo. We'll give the rest more attention, starting with create.\par
$ docker service create --help | more\par
This is the equivalent of docker run for swarm services. There are too many options to go through. Several match docker run options and several others are unique to services. We'll go through some of the unique ones in this lesson and save some for the next.\par
Let's start by creating the swarm visualizer. The visualizer must run on managers, so we can use a constraint on the node role to handle that. For demonstration purposes, I'll make the service global so that every manager will run one task for the service. The service could be load-balanced since the swarm state that the service visualizes is the same regardless of which manager you use. But I will publish the port using host mode so we can compare that to ingress mode. Ingress mode is the default, so the mode=host part of the string must be provided. The mount option is required so that the service containers can access the manager node's docker daemon socket. That is where it pulls the swarm state information from. Finally, we'll give the service the name viz and specify the latest version of the dockersamples/visualizer image.\par
\par
$ docker service create \\\par
--constraint=node.role==manager \\\par
--mode global \\\par
--publish mode=host,target=8080,published=8080 \\\par
--mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\\par
--name=viz \\\par
dockersamples/visualizer\par
\par
The commands can get pretty long and we'll see how to bettern manage them in the next lesson. I'll speed things up until it is finished. The service converged message lets us know that the actual state has converged to the desired state in the service spec. We can see the service spec using inspect\par
$ docker service inspect viz --pretty | more\par
This output shows some of the default values that were used, such as the update and rollback config. It also shows that the service mode is global and that the port has been published in host mode. We can use the ps command to confirm the actual state matches the desired state\par
$ docker service ps viz\par
\par
Now let's switch over to a web browser to see the swarm visualizer. The manager is running on vm1 which has an IP address of 192.168.99.100. The visualizer displays a column for each node. The node's name, role, memory, operating system, and the hard to read text is the node labels we applied earlier. Tasks are shown with squares under each node's heading. Currently there is only the one visualizer task. If we didn't have any role constraint there would be one on every node, but because the service was constrained to managers, there is only one. Task borders are color-coded according to their service. Because the service published its port in host mode, I have to use the manager's IP. If I try vm2's IP, it won't be able to reach the service. So I'll go back to vm1's IP address.\par
I'll promote vm2 to be a manager and that will cause a viz replica to be started on vm2 because the viz service is global. I'll use the ls command to see the change. Notice the replicas has jumped up to 2. After awhile there will be 2 of 2 tasks running and I can try again to access the visualizer on vm2 in the browser. There it is. Both vm1 and vm2 are manager's and there are two replicas of the viz service shown. I'll go back to vm1's visualizer and demote vm2 back to a worker. Now we're back to just one viz replica.\par
Let's focus in on the 2nd service now. I'll switch over to VS Code and quickly go through the source. This file, index.php, is doing going to echo back the node name which it gets from an environment variable. That's all there is to it. Taking a look at the Dockerfile, the base image is an php image with the apache web server installed. The index.php source file is copied into the image and the web server serves it on port 80. There is also a healthcheck embedded in the image. You can of course override the image healthcheck or create a healthcheck if the image doesn't have one when you create the service. This is the same behavior as with docker run.\par
Back to the command line. We'll create the service with a constraint to not schedule any tasks in zone 1. The exclamation mark followed by equals means not equal to. We'll declare 2 replicas. This implies the service mode is replicated and not global. replicated is also the default. The manager will try to spread the tasks over available nodes by default, but we will specify a placement preference to take control of how it spreads. Next, I'll add an environment variable for the NODE_NAME and use a Go template to get the hostname of the node. Port 80 will be published in ingress mode by default making the service reachable from any node's IP address regardless of if a task is running on the node. I'll give the service the name nodenamer and specify version 1.0.0.\par
\par
$ docker service create \\\par
--constraint node.labels.zone!=1 \\\par
--replicas 2 \\\par
--placement-pref 'spread=node.labels.zone' \\\par
-e NODE_NAME='\{\{.Node.Hostname\}\}' \\\par
--publish 80:80 \\\par
--name nodenamer \\\par
lrakai/nodenamer:1.0.0\par
\par
Now the two tasks move through the preparing, and starting states to reach the running state before the service converges to the desired state. We can check on the swarm state in the visualizer. There are two tasks for the nodenamer service and they have a dark grey border. They are deployed evenly across all the zones except zone 1 as we constrained the placement. We can also test the ingress routing capabilities. I'll send a request to port 80 on vm1 which isn't running a task for the service. But the page loads thanks to the ingress routing mesh. if I reload a few times, you can see the node name changing. This illustrates the virtual IP load balancing of the service. If I send my requests to vm2, the behavior is the same.\par
\par
Back at the command-line I can also access the service at localhost on vm1 through the ingress network.\par
$ curl localhost\par
The output doesn't have new line so the command prompt gets tacked onto the end. Version 1.0.1 of nodenamer fixes this issue. We'll do a rolling update to version 1.0.1. Before we do, we can inspect the service\par
$ docker service inspect nodenamer\par
and observe the setting for updates. Parallelism is one by default so only one task will be upgraded at a time. We won't look at failed updates, so the only other relevant setting is update order which is only available in Docker 17.05 and above. It defaults to stopping existing tasks and then starting a new task. The other value is start first, which starts a new task first and then stop the old one when the new task is running. There's also update delay which sets the delay between rolling updates. It defaults to zero which is not a problem in this case, we'll still be able to see the update roll through because it takes some time for new tasks to get to running. Let's do the update to version 1.0.1\par
$ docker service update --image lrakai/nodenamer:1.0.1 nodenamer\par
And switch over the the visualizer to watch the update roll through. The old task on vm2 is taken down first, then a new task using the 1.0.1 image comes in. As soon as it reaches the running state, the task on vm3 is stopped and a new 1.0.1 image task starts.\par
Now if I curl localhost from vm1, the new line is added to the output.\par
We can scale up the service to, say 6 replicas using the scale command\par
$ docker service scale replicas=6\par
and we will see them come up equally spread across the eligible nodes. Even though there are more than one task on each node there are no port conflicts. This wouldn't be the case if host mode was used for publishing the service port.\par
Let's set the parallelism for rollbacks to 2 so we can rollback faster than we update.\par
$ docker service update --rollback-parallelism 2\par
Then we intentionally update the service back to version 1.0.0 so we can finish the lesson with a rollback to version 1.0.1.\par
$ docker service update --image lrakai/nodenamer:1.0.0 nodenamer\par
And we can see it roll through 1 task at a time.\par
Now we can rollback \par
$ docker service rollback nodenamer\par
and we should see two tasks at a time being rolled back. There we see it rolling back two at a time.\par
That's it for this lesson. You now know how to put the theory we studied earlier into practice by using the docker service management command for managing services.\par
\par
Closing\par
In the next lesson, we'll cut down on the lengthy commands and improve the repeatability and maintainability of swarm service deployments by using stacks. Whenever you are ready, continue on to the next lesson.\par
\par
\par
\b\fs32 Working with Stacks\b0\fs22\par
\par
Stacks help you manage applications distributed across a swarm. In this lesson, we'll get some practice working with stacks. I think you'll find that it's easy to get the hang of and better than writing sprawling, multi-line docker service create commands.\par
Agenda\par
We'll start the lesson by introducing stacks and stack files. It won't take very long because your prior experience with Docker Compose will serve you well here. Then we'll get started with a demo. Our last demo of the course.\par
\par
Stacks\par
In swarm mode, stacks are a group of related services that can be orchestrated and scaled together. It carries the same meaning as a software stack or technology stack in application development.\par
Stacks are declared using a Compose file. That makes it very easy to start using stacks given your Docker Compose experience. You can use stacks to manage services, networks, and volumes as you would with Docker Compose. For a compose file to work as a stack, you have to be using Compose file version 3 or greater. Although they are the same type of file, when you deploy an application declared in a compose file to a swarm, it's referred to as a stack. By convention, the file name that is used to indicate a stack is docker-stack.yml.\par
A lot of the Docker Compose features you know and love work with stacks. These include the declarative configuration, an active community on Github, and the benefits of source-controlled configuration. Similar to Compose, when you deploy a stack a network is created by default to isolate the stack from other services.\par
However, there are some differences between using Docker Compose and stacks that you should be aware of. Currently, there are several configuration options that are ignored with stacks that you could use in Compose. Some of the most notable ones are build and depends_on. The Compose file reference documentation should be consulted as support is added/removed for options over time. A link to the documentation is at the bottom of the transcript for this video.\par
On the flip side, what's stacks can use that Compose can't are mostly gathered under the deploy key. That is where you can specify options for node labels, replication mode, resource reservations, update configuration, and others. Currently, there isn't support for configuration rollbacks in a stack file, and placement preferences and endpoint_mode for setting virtual IP or DNS round robin service discovery are only available in version 3.3 Compose files or above. Stack files also support swarm secrets by a top-level secrets key. We won't get into the details but know that they are supported.\par
With previous experience in Compose, that's all that we need to go over to start using stacks in swarm mode. We can get started with the demo which will reproduce what we did in the last lesson's demo except using stacks.\par
\par
Demo\par
I'll start by removing the currently running services we deployed with docker service create, since we're going to recreate them using a stack.\par
$ docker service rm viz nodenamer\par
\par
Now let's take a look at the stack file. I won't dwell on it since it is a one-to-one mapping of the commands we entered to create the services before except with more structure and slightly different option names. The stack specific options are under the deploy keys. Because we have a placement preference, we need to use version 3.3 or higher. It is more pleasant to work with stacks compared to entering all the options at the command-line. We'll also see next that commands for stacks can limit output to services declared in a stack without having to do any filtering.\par
The commands for working with stacks are organized under the docker stack management command\par
$ docker stack --help\par
ls lists the current stacks, services lists the services in a stack and ps lists all the service tasks for a given stacks. The deploy and rm commands are similar to docker-compose up and down. In fact, up and down are aliases for deploy and rm so you could use up and down with stacks if you prefer.\par
\par
Let's look at the deploy options\par
$ docker stack deploy --help\par
You have options for removing services that are no longer in a stack, controlling when images are resolved, and for passing along credentials if you are using images in a private Docker registry. The one required option is -c to specify a Compose file for the stack.\par
$ docker stack deploy -c docker-stack.yml demo\par
I'll call the stack demo. We can see the stack has a network created automatically for the services in the stack. Of course, you can, and often should, exercise more control over the networks you want, just as you would in Docker Compose. The stack has finished deploying so we should see the visualizer on port 8080 of vm1, and there it is.\par
To do an update you use the same deploy command you used with the original stack deploy. Let's make an update to the stack so there are 6 replicas, and let's also put a resource reservation of half a cpu for each nodenamer replica. Each vm only has one cpu so there won't enough cpu available for all 6 replicas. We'll use this to verify that swarm respects the resource constraints. Re-run the deploy command \par
$ docker stack deploy -c docker-stack.yml demo\par
The configuration changes will be detected, and the swarm leader will bring the swarm to the new desired state. Let's watch the visualizer to see what happens. We can see 2 new tasks starting on vm2 and then another on vm3. After all the tasks on vm2 are running one is stopped to respect the resource reservations. We can also see from listing the services in the stack that only 4 of 6 tasks for nodenamer are running while two are left pending.\par
That's all for this demo and this lesson. We saw that working with stacks is a natural extension of Compose files and docker commands.\par
\par
Closing\par
We've almost reached the finish line now! Join me for the final lesson when you're ready to wrap up the course.\par
{{\field{\*\fldinst{HYPERLINK https://docs.docker.com/compose/compose-file }}{\fldrslt{https://docs.docker.com/compose/compose-file\ul0\cf0}}}}\f0\fs22\par
}
 