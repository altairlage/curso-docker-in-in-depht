{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1046{\fonttbl{\f0\fnil\fcharset0 Calibri;}{\f1\fnil Calibri;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 10.0.17134}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\b\f0\fs32\lang9 Course Introduction\b0\fs22\par
\par
Welcome to managing applications with Docker Compose.\par
\par
About Me\par
I\rquote m Logan Rakai and I\rquote ll be your instructor for this Course. I\rquote m a content researcher and developer here at Cloud Academy. I\rquote ve mostly worked on developing Labs, but I\rquote m excited to be your instructor for this course. I\rquote ve put a lot of thought into it and I hope you enjoy it. I have over ten years of experience in software research and development including five years in the cloud. I\rquote m an AWS Certified DevOps Engineer Professional and a Microsoft Certified Solutions Expert: Cloud Platform and Infrastructure. You can connect with me on LinkedIn or on Twitter.\par
Who this course is for\par
This course is for anyone who could find themselves working with Docker containers. Among the roles that might be in that situation are DevOps engineers, developers, cloud engineers, and test engineers.\par
\par
Prerequisites\par
In order to get the most out of this course, you should have experience with Docker. You probably have enough experience if you have ever written a Dockerfile or if you can answer questions like when should you use a volume? And when should you use a user-defined network? The course includes some development demos that are most beneficial if you have some software development experience. You can follow along and I\rquote d encourage you to. You will need Docker version 1.13 or greater installed. I\rquote ll be using a Mac with Docker for Mac installed but you can follow along in Linux or Windows. The code I\rquote ll be using is all available on GitHub. A clickable link is available at the bottom of the transcript for this lesson. You\rquote ll benefit from a good integrated development environment or IDE. I\rquote ll use Visual Studio Code which is available for free on mac, Linux, and Windows.\par
\par
What we\rquote ll cover\par
In this Course, we\rquote ll go over what Docker Compose is and why you would use it. Then we\rquote ll explore the two parts of Docker Compose: Docker Compose files and the Docker Compose command-line interface. Next, we\rquote ll get into demo-focused lessons beginning with running a web app with Compose. After that, we\rquote ll see how to build images in a development scenario with Compose. Lastly, we\rquote ll see how to use Compose to adapt an application to multiple different environments. In particular, we\rquote ll see how to use Compose to manage an application in development and production. Wow, after seeing all those exciting topics I need a second to Compose myself.\par
Learning Objectives\par
After completing this course, you will be able to: \par
\f1\bullet  Understand the anatomy of Docker Compose files\par
\bullet  Configure your application using Docker Compose files\par
\bullet  Use the Docker Compose CLI to manage the entire lifecycle of applications\par
\bullet  Build your own images from source code with Docker Compose\par
\bullet  Extend Docker Compose files to adapt applications to multiple environments\par
\par
Feedback\par
I\rquote m happy to hear from you. I make content for you and I want it to be as good as it can be. If you have any feedback, please get in touch with me by leaving a comment on the Comments tab below the video, by emailing support@cloudacademy.com, or by connecting with me on Twitter where my handle is @LoganRakai.\par
All right, that\rquote s all for the introduction. In the next lesson, we\rquote ll start to get a better idea of what Docker Compose is. Continue on to the next lesson whenever you are ready.\par
{{\field{\*\fldinst{HYPERLINK https://github.com/cloudacademy/docker-compose-training }}{\fldrslt{https://github.com/cloudacademy/docker-compose-training\ul0\cf0}}}}\f1\fs22\par
\par
Docker Compose Overview\par
\par
Agenda\par
I will begin by looking at how you might accomplish a task without Docker Compose. This will highlight some of the issues that Docker Compose was made to solve and give motivation for this lesson and really the entire course on Docker Compose.\par
Then I will define Docker Compose at a high level in terms of what it can do and how it does it.\par
Lastly, I will introduce the two parts that make up Docker Compose.\par
By the end of this lesson you will understand what Docker Compose is, why you would use it, and get to know a bit about the parts that make up Docker Compose.\par
\par
A world without Docker Compose\par
Ok, to start off with, I want share the motivation for Docker Compose and it will give an opportunity to review some core Docker concepts. Let\rquote s say that you are working on developing an application with Docker. The application is relatively simple, consisting of two services that communicate with one another. Each service corresponds to a container in the diagram. One service, let\rquote s call it service A, is entirely stateless and should be accessible from the host machine on a port. The other service, service B, is required to persist data. You have Dockerfiles for both services already.\par
The task at hand is, to spin up a temporary environment with the application running to perform some tests and tear it down when you are finished. How do you create this environment?\par
In a world before Docker Compose, you might go about achieving that with the following series of Docker commands. You want to follow best practices in isolating your application\rquote s containers from other containers that are running on the Docker host. To give you the most control over that you create a user-defined bridge network:\par
$ docker network create --driver bridge app_network\par
Using a user-defined network also gives you access to automatic DNS resolution from container names to IP addresses that your application might take advantage of.\par
For service B that persists data, you want to follow best practices again by choosing an option that is easy to back up and migrate, that can be managed using the Docker commands, can be safely shared among multiple containers, and have the flexibility to be stored on remote hosts or in the cloud. You naturally decide to create a volume to achieve this:\par
$ docker volume create serviceB_volume\par
\par
Now you build the Docker images using docker build with the \endash f option to specify the different Dockerfiles for each service:\par
$ docker build -f Dockerfile.serviceA .\par
$ docker build -f Dockerfile.serviceB .\par
\par
Almost there. You only need a couple more commands to start running the containers using the images you built. The docker run command creates the containers and starts running them. You use the \endash network option so that both containers are in the app_network in order to communicate. You use the -p option so that Service A is accessible on a host port. You use the --mount option to service B\par
$ docker run -d \endash name serviceA \\\par
--network app_network \\\par
-p 8080:3000 \\\par
serviceA\par
$ docker run -d --name serviceB \\\par
--network app_network \\\par
--mount source= serviceB_volume,target=/data \\\par
serviceB\par
\par
Now everything is up and running so you can perform some tests\par
\'85 \'85. Hmmm \'85 \'85 ah yes\par
After your tests are completed you decide to tear down everything you created to keep the environment pristine\par
\par
$ docker stop serviceA serviceB\par
$ docker rm serviceA serviceB\par
$ docker rmi serviceA serviceB\par
$ docker volume rm serviceB_volume\par
$ docker network rm app_network\par
\par
And that\rquote s it.\par
Now let\rquote s take a moment to discuss the solution in the grand scheme of things. Relatively speaking, it is not too bad compared to a solution using virtualization and even better when compared to what would be involved using bare metal. Docker has made great progress in creating environments quickly and without having to worry about nasty issues like configuration drift.\par
Now, the series of commands used isn\rquote t the minimal number you could use to achieve the same result. For example, you might decide that it is acceptable to have Docker automatically create the volume for you as a side effect of the \endash mount option in the run command instead of explicitly creating the volume with docker volume. But even after some optimizing, the fact remains, there is a lot of typing involved to accomplish a fairly common task. Not to mention there could easily be more options involved for configuring each command.\par
\par
\par
Can we do better?\par
However, it is natural to ask the question, can we do better? One option that could be useful when performing the commands more than once is to put all the commands in a script. That also allows you to check the script into version control to better manage changes and collaborate with other team members. But to write the script you still need to know all of the docker commands required and the sequence to put them in. You are in essence telling Docker how to do something with the commands in the script. This is sometimes referred to as the imperative paradigm in DevOps where you give explicit steps to perform.\par
As an alternative, wouldn\rquote t it be nice to only have to declare what you want to make instead of the explicit steps to perform to create what you want? That is to take a declarative, as opposed to an imperative, approach and let some tooling figure out the steps to create what you want. \'85Wait for it\'85\par
\par
What is it?\par
That is in essence what Docker Compose gives you with respect to defining and managing multi-container environments in Docker. You still get the benefits of being able to use source control, but the emphasis shifts to describing what you want instead of how to create it. By way of analogy, Docker Compose is similar to using Dockerfiles. You can run a container, attach to it, run some commands, and use Docker commit to create a new image from the container. But in most situations, you want the enhanced documentation and maintainability that a Dockerfile gives you for accomplishing the same task along with Docker build. Analogously, you usually want to use Docker Compose instead of running a series of Docker commands.\par
That gives you a high-level understanding of what Compose is and why you might use it. In the context of Docker, you can refer to Docker Compose simply as Compose. You will see a lot of examples of Compose in action throughout this course to develop a more robust understanding of Compose.\par
It is also worth noting that Docker Compose files can be used to manage multi-container applications that are distributed over a cluster of computing resources. To natively manage a cluster in Docker, you run Docker in swarm mode. Swarm mode is outside of the scope of this course. You can learn more about swarm mode in other excellent content on Cloud Academy. I just want you to know that the time you spend learning Docker Compose in a single host environment will pay dividends later on when you start running applications on a Docker swarm cluster.\par
\par
 \par
\par
Parts\par
Docker Compose consists of two parts: a specially formatted file called a Compose file, and a command-line interface.\par
A Compose file is where you declare services that comprise your application. You can do a lot inside a Compose file. The Docker commands you use for creating containers, volumes, and networks have equivalent declarative representations in Compose files. Knowing Docker commands makes writing Compose files quite easy given their close connection.\par
There is an entire lesson devoted to the details of Compose files in this course. To get a sneak peak of what\rquote s to come, take a look at this example Compose file. The services section declares two services: web and redis. Each service has a set of options underneath it. For the web service, there\rquote s an option for specifying the image, which ports to make expose on the host machine, and a volume to mount in the container created for the service. There is also the depends_on option which isn\rquote t something that has an equivalent docker command option. It becomes necessary in the context of Compose because you need a way to specify the order services come up. You can no longer issue commands in a specific order as you would with docker commands. But I\rquote m getting ahead of myself. We\rquote ll cover a lot more details on Compose files in an upcoming lesson.\par
The other part of Compose is a command-line interface. It has a familiar feel to the docker command-line interface. Many of the commands you use with docker exist in docker-compose but generalized to multi-container applications. The name of the Compose binary is appropriately docker-compose. As an example of the power of docker-compose, the series of\par
docker commands that was presented in the Motivation section can be performed with just two commands in Docker Compose. One for bringing the application up, and another for tearing everything down. The simplicity of creating isolated environments with Docker Compose makes automated testing one of its key use cases. As with Compose files, there is an entire lesson in this course devoted to the Compose command-line interface. You will also see a lot of both Compose files and command-line interface in all of the lessons that present examples showing you how to use Compose for different tasks.\par
\par
\par
Recap\par
It can be difficult to manage multiple container applications. In the example at the beginning of this lesson, many commands and options are required to start and stop a relatively simple multi-container application. The difficulty in managing multi-container applications grows with the number of containers involved.\par
Docker Compose lets you specify services in a multi-container application using a declarative paradigm. You declare what you want and Compose figures out how to create it.\par
There are two parts to Compose. Compose files are where you declare the services you want, and the docker-compose command-line interface is how you manage the multi-container application declared in a Compose file.\par
That\rquote s all for this overview lesson on Docker Compose. We\rquote ll dive deep into Compose files in the next lesson. Whenever you are ready, continue on and start to see your multi-container applications through the Docker Compose lens.\par
\par
\par
\b\fs32 How to Create Docker Compose Files Using YAML\b0\fs22\par
\par
\f0 Agenda\par
I will start by giving you a brief introduction to the file format used for Compose files: YAML. If you haven\rquote t used YAML before, you\rquote ll learn enough to understand the Compose file examples used in this course.\par
Next, I will teach you about the root elements in a Compose file document. These are the top-level element of a Compose file and include: Compose file version, services in the application, volumes used by the services, and networks to be created. There is a lot of similarity between these sections of a Compose file and Docker commands that you are familiar with.\par
I will finish the lesson with a couple special topics in Compose files. \par
Let\rquote s get started with YAML.\par
\par
YAML\par
\par
YAML is a data serialization language. Data serialization languages can be employed for a broad variety of programming scenarios including internet messaging, object persistence, or, in the case of compose, configuration files. Some of the design principles of YAML are that it should be human-friendly, and that it should work with any programming language. When YAML is stored in a file, the file can have a .yaml or .yml extension. Both are recognized as YAML. The capabilities outlined in the YAML specification are quite extensive. We\rquote ll only really scratch the surface of what you can do with YAML.\par
Another, perhaps more common, data serialization language is JavaScript Object Notation (JSON). JSON formatted files are supported by Docker Compose. However, it is rare to see JSON Docker Compose files in practice. Comparing a YAML file to its JSON equivalent shows the cleanliness and fewer characters needed to represent the contents. In this example, Part of the reason why it can cut down on the line count is because it is whitespace sensitive. That means if you insert an extra space at the wrong place, the file will be corrupted. JSON on the other hand isn\rquote t whitespace sensitive, meaning that you could squash all the whitespaces out and not harm the integrity of the file. However, readability would not fare so well. For that reason, JSON files tend to be formatted with abundant whitespace resulting in a less compact representation than YAML. It can take some getting used to working with a whitespace sensitive language, but IDEs tend to have support for formatting YAML files making it quite painless to work with. Some features of YAML, which is actually a superset of JSON, further enhance the compact representation of Compose files. You will see an example of this later in this lesson.\par
\par
Data Types\par
Let\rquote s take a look at a few basic data types in YAML. This list isn\rquote t comprehensive but is enough to understand what usually goes into Compose files.\par
The first YAML data type we\rquote ll consider are integers. Integers are whole numbers like zero or 1. You can also include a leading plus or minus sign to indicate positive or negative integers.\par
Strings are a sequence of characters that aren\rquote t interpreted as a different data type. Strings can include spaces and the use of quotes to indicate the start and end of a string. Quotes are optional unless you use symbols that have a special meaning. Use single quotes around strings that use YAML syntactic characters like the pound symbol or colon. Use double quotes if you want to escape control characters like backslash n for newlines. If you want an integer to be interpreted as a string, you need to enclose it in quotes because it will be interpreted as an integer otherwise.\par
The null type is used to represent the absence of a value, or no value. It isn\rquote t very common to see in Compose files but is a recognized data type in Compose. You use a tilde or the word null to represent it.\par
\par
Booleans\par
Booleans are the last data type we\rquote ll discuss. They indicate one of two values: true or false. Booleans can be represented with true, false, yes, no, on, off as well as the same words with the first letter capitalized or all the letters capitalized. In YAML any matches of a pattern including yes, and on get converted to true. This can cause unintended consequences if you have conditions testing Boolean values. For example, if you had a condition that was checking if a variable has a Boolean value of yes but it automatically got converted to true. Compose simply disallows the use of Booleans in contexts where such issues can arise to be on the defensive side.\par
You\rquote ll see an error message similar to this if you use a Boolean value. In this particular case, I tried to use a Boolean as an environment variable. As the error message hints, only strings, number, or a null can be used. If you want to use true or false, yes or no, on or off as values, you need to use the string representation by wrapping them in quotes. If you ever encounter an error message involving true or false, this is probably what it relates to.\par
\par
Collections\par
Collections are data structures that allow you to collect basic data type values in an organized manner. The first YAML collection we\rquote ll consider is the mapping. Mappings are also known as dictionaries or hashes in different programming languages. Maps consist of keys mapped to values. The syntax for a mapping is a key followed by a colon, a space and then the value. The space is important. A mapping can have multiple key value pairs.\par
Mappings can also have mappings as values. Using a mapping as the value for a mapping is referred to as nested mappings. In Compose files the inner mapping is usually located on a new line with indentation.\par
There is also an inline syntax that lets you write a nested mapping on a single line. You use braces to wrap the inner mapping in this case. You may see this from time to time but I think it tends to hurt readability and should be avoided.\par
\par
Sequences\par
The other kind of collection is a sequence. Sequences are also called lists or arrays in other languages. Sequences are simply lists of values.\par
You use dashes to indicate items in a sequence. Each item goes on its own line at the same level of indentation\par
Sequences can also be nested. To represent an inner sequence, you use an indented dash on a new line below the outer sequence.\par
As with mappings, there is an inline syntax to represent a sequence on a single line. You use brackets to wrap a comma-separated list of items to use inline syntax. You see this inline syntax used for command options in Compose files.\par
\par
Combos\par
You can also combine the sequence and mapping collections. For example, you can have a sequence as the value of a mapping. The dash in a sequence as a mapping value also counts as indentation, so you don\rquote t have to use spaces for indentation when including a sequence in a mapping. That means both of these examples are valid YAML. You might prefer to indent for consistency, but they are not required and you will see both styles used in practice.\par
Similarly, you can use mappings in a sequence. There is again two ways to represent a mapping in a sequence. You can use a line with only a dash followed by the indented mapping, or you can include the first line of the mapping on the same line as the dash. Both styles get used and you should be aware of each.\par
The last thing I want to mention about YAML is that is supports inline comments. This makes it much more useful in terms of documenting Compose files than JSON which doesn\rquote t support commenting. In YAML, a comment starts when a pound character is encountered and continues to the end of the line. The exception to a pound character starting a comment is if it\rquote s within a quoted string.\par
That is enough YAML to get through the example Compose files used in this course. It\rquote s also enough to understand most examples you might find online and enough for you to write your own Compose files. As I mentioned before, using an IDE that can automatically format YAML can save you some headaches. Compose also includes a command for verifying configuration files in case you need to verify your YAML syntax and configuration declared in a Compose file.\par
\par
\par
Compose files\par
Now that we\rquote ve built up a foundation in YAML, we can focus on Compose file specifics. As mentioned earlier, YAML Compose files are the focus and make up the vast majority of Compose files in use. We will only consider version 3 Compose files.\par
From this compatibility table, you can see that version 3 Compose files require a Docker Engine of version 1.13 or higher. The Docker Compose command-line interface has a different release schedule than the docker engine, and requires version 1.10 or high for version 3 Compose files. Docker recommends using version 3 Compose files. There are multiple minor version numbers for version 3, for example 3.0 and 3.4. Unless otherwise noted, examples used in this course follow the 3.0 Compose file format. This covers versions of Docker released since the beginning of 2017.\par
{{\field{\*\fldinst{HYPERLINK https://docs.docker.com/compose/compose-file }}{\fldrslt{https://docs.docker.com/compose/compose-file\ul0\cf0}}}}\f0\fs22  The Compose file reference is a great reference for understanding all the configuration options available to you in Compose files. This course covers many frequently used configuration options, but leaves out many that might be useful in certain situations. Let\rquote s take a quick look at it now.\par
Here we are at the Compose file reference page. It defaults to showing reference material for the latest major version which is 3 at this time. There is a handy navigation bar on the right to see all the available configuration options\par
Just note that it can be confusing at times because some configuration options only apply to Docker swarm mode (deploy), some only apply when not running in swarm mode (security_opt), or specific Compose file minor versions (Extension fields), and sometimes different options are available for Docker running on Linux or windows based systems (isolation).\par
\par
Version\par
A YAML Compose file is a mapping with several keys at the root or top level. The first one we\rquote ll discuss is the version. The value for the version must be a string. The string can specify a major version number only, for example 3, or a major and minor version number, such as 3.1. If a only major version is included, the minor version is implied to be 0, or the earliest release. So if you want to use a feature that came out in the latest minor version release, you need to include it in the version string. The version string tells Compose how the contents of the file should be parsed.\par
\par
Services\par
The services mapping is where you configure the containers created for services in your application. Each service is configured in a nested mapping under the services key. You can assign an arbitrary name for each service. In the image, the service names are web and redis. Each service has a nested mapping that declares the configuration for containers started for the service. The configuration is the main piece of declaring services in a Compose file, so let\rquote s focus in on that.\par
\par
Configure the container for the service.\par
Inside of the service configuration mapping, you declare the configuration options for service containers in a way that is similar to how you would configure containers using docker run command parameters.\par
\par
This table shows how you would configure a container using the docker run command and the corresponding configuration key in a Compose file. The only required argument for docker run is the image name, which you specify using the image key in a Compose file. There are a few ways to configure a volume with docker run, but they all map to the volumes key in Compose files. There are different syntaxes in Compose to support the different volume configurations that you use different parameters for with docker run. The -p parameter to publish ports on the host corresponds to the ports key in Compose files. The -e parameter for setting environment variables in a container maps to the environment key in Compose files. With docker run you have two parameters for setting up logging and both parameters go into a nested mapping under the logging key. The last one that I\rquote ll mention is security-opt for setting security options which only differs in the use of an underscore in Compose files. There are many more, but aside from a using YAML and slightly different names your experience with docker run will make writing Compose files easy.\par
\par
Caveats\par
There are some points to be aware of for the correspondence between docker run and Compose file service configuration. Some docker run parameters that you might expect to be able to use in Compose only work in swarm mode. This is the case for setting runtime constraints such as -m for memory limit, or --cpus for number of cpus. It\rquote s possible to run Docker in swarm mode with a single machine so it isn\rquote t a significant barrier. However, Swarm mode is outside of the scope of this course so that\rquote s all I will say about it.\par
Other docker run parameters such as -d to run in detached mode or --rm to clean up the container when it exits are specified through the command-line interface and not in the Compose file configuration.\par
\par
Dependencies\par
Because Compose supports multi-container applications, there are additional options for configuring services that don\rquote t exist with docker run.\par
The depends_on key provides a way to list the services a service depends on. Docker Compose can use the dependency relationships to determine the order to start services. If you tell Compose to start a specific service instead of the entire application, Compose can also use the information to automatically start any dependencies of the service. However, it\rquote s important to note that Compose won\rquote t wait for the dependencies to be ready before starting a service. For example, Compose can start a database before a web service but it can\rquote t account for the time it takes the database process to be ready to handle connections. Because of this, it\rquote s best practice to write your applications in a way that can tolerate connection failures. If that isn\rquote t an option, you can use scripts that poll the dependencies to wait until they are ready. One such script is called wait-for-it.sh.\par
The other key that expresses dependencies is links. Links correspond to the link parameter of docker run allowing you to grant access to a container to access an exposed port on a private interface and to provide aliases to reach containers. Links in Compose carry the same meaning but additionally determine startup order of services, the same way depends_on does. Generally, networks are a better way to express communication relationships. We\rquote ll discuss more about networks in a bit.\par
\par
Examples\par
To get a taste of service configuration in Docker Compose, let\rquote s look at some examples. I\rquote ll arbitrarily use the redis image for the examples. Starting off simple, this docker run command will start a container named app-cache using the redis image.\par
The equivalent service configuration in a Compose file would like this. In the first line we need to specify that we are using version 3 of compose files. The services mapping is a pretty simple conversion of the docker run command parameters. The container name used as the service key, and the redis image argument used as the image key-value pair.\par
Now, if you specify a tag to pull a specific version of the image,  you add the same tag to the image value. Note that although the colon is a special character in YAML, you don\rquote t need quotes around the string because colon only takes on special meaning when followed by a space.\par
If you want to the redis server port of 6379 available on the Docker host, you include the -p argument like so.\par
The corresponding Compose file includes a ports key which has a sequence of port strings. Just like with Docker run you can specify host and container port, or just the container port to allow Docker to choose an available host port. When specifying host and container port like in the example, it\rquote s a good idea to put quotes around the string because YAML will parse numbers separated by a colon as sexagesimal or base 60 numbers if the numbers are less than 60.\par
In this last example, a command with arguments is added to override the default command.\par
The same string can be used as the value of the command mapping in a Compose file.\par
Or you can use the same syntax you would use in a Dockerfile for setting the default command of an image. In this case you do need quotes around the last argument \ldblquote yes\rdblquote  otherwise it gets treated as a Boolean value. It\rquote s best to always quote as you would in a Dockerfile. You might also recognize that syntax as the inline syntax of a sequence.\par
That means you can also express the command in the normal sequence syntax. This form can make long commands more readable. You get the idea of how to work with service configuration in Compose files through these examples. You might need to consult the Compose file reference to get the correct key names but it\rquote s usually a fairly straightforward exercise to write the configuration.\par
\par
Volumes\par
The next root key in the Compose file mapping is volumes. It is an optional key. You use the volume mapping in a way that is similar to how you use docker volume create. Services can reference volumes in each service\rquote s volumes configuration key.\par
It\rquote s a good time to point out that you can use volumes in the service\rquote s configuration even if you don\rquote t have a volumes key in your Compose file. The use case for the root volumes key is to use named volumes and to share volumes across services.\par
You can also declare external volumes that have been created outside of the context of the Compose file. For example, a volume created by docker volume create, or a different compose file. In a volume\rquote s nested configuration mapping, you can set the external key to true to declare an external volume. If the external volume doesn\rquote t exist, an error will be reported.\par
Take a look at this example Compose file using the root volumes key. There are two named volumes declared on lines 13 and 14. The first, called named-volume, doesn\rquote t have any nested configuration. This will create a volume using the default local volume driver. YAML sees the absence of any value and represents it as a null. You could equivalently write a tilde or the word null for the value on line 13. The other named volume is called external-volume and is configured as an external volume.\par
In the app-cache service\rquote s volumes configuration starting on line 5, you can see a few ways to declare volumes in Compose. The first is using a named volume in the root volumes key and will be mounted at /data in the container. The next example on line 9 uses a relative path to set the source of the mount. Relative paths are relative to the location of the Compose file. The last example on line 11 will have the Docker Engine create a volume automatically to mount at /tmp/stuff in the container.\par
Lastly for volumes, you can configure a custom volume driver using the driver and driver_opts keys. The named volume in the example called ebs-volume uses the convoy docker volume plugin by rancher. If you want to specify any driver-specific options, you can do so under the driver_opts key.\par
\par
Networks\par
Networks are declared under the top-level networks key. By now it will come as no surprise, that network configuration in Compose files aligns closely with the docker network create command. However, there are a few new concepts to networking in Compose.\par
By default, Compose will automatically create a new network using the default bridge driver for an application in a Compose file. The name of the network is based on the name of the directory the Compose file is in with default appended on the end. All containers created for services in the Compose file join the default network and can be reached and discovered by the corresponding service name. This is slightly different from running containers with docker run and not specifying a network. In that case, the containers get added to the default network named bridge.\par
To review how you can use a bridge network, consider this example Compose file. There are two services, web, and cache. The Compose file doesn\rquote t declare any networks so all service containers will join the default network created for the app declared in the Compose file.\par
In the default network, the cache container can reach the web container by using web as the hostname for the container.\par
Similarly, web can reach cache by resolving the cache hostname. Because web is inside the network, it uses the container port of 6379 to connect.\par
From the Docker host machine, cache can be reached at the host port of 36379. What about web? How can the host reach web?\par
It cannot reach web, because no ports are published making it accessible to the host.\par
Besides the default network, you can declare custom networks under the root networks key. This gives you more control and allows you to create more complex network topologies. Custom networks can be external to the application, similar to external volumes worked. You add the external: true mapping to tell Compose to verify the network already exists and join services to that external network.\par
This example Compose file illustrates how custom networks are used. The file declares two networks under the top-level networks key beginning at line 18. The frontend network uses the default network configuration, while the backend network refers to an external network created outside of the Compose file. The networks mapping for each service shows the proxy and app service are part of the frontend network, and the app and db service are in the backend network. With this configuration, the db and proxy services are isolated from one another. This approach of limiting communication between services to allow only what is necessary is a best practice. The db service further configures the alias database for itself on the backend network. The app container could resolve the hostname db or database as a result of the alias. The mapping syntax must be used for specifying aliases.\par
\par
Special Topics: Variable Substitution\par
I will finish of the lesson by discussing a couple special topics in Compose files, starting with variable substitution. Variable substitution allows you to generalize your Compose files to create different environments without having to modify the Compose file. Docker Compose will substitute shell environment variables in place of variable placeholders in a Compose file. You indicate a variable by using a dollar sign before the variable name, and optionally surrounding the variable name in braces. If the variable is not defined in the environment where Docker Compose is running, an empty string is substituted for the variable. The example on the bottom half of the slide shows a snippet of a Compose file that uses a variable named REDIS_TAG for the image tag. In the shell environment, the REDIS_TAG environment variable is set to 4.0.5. When Docker Compose creates the application, the environment variable is substituted into the image value string.\par
\par
Special Topics: Extension Fields\par
The other special topic I wanted to mention is extension fields. Extension fields let you reuse configuration blocks and move important configuration fragments to the root of the Compose file. Extension fields only work with version 3.4 or higher Compose files, so you will need to include a minor version number to get this to work in version 3. To use extension fields, add a root key that begins with x- and add the configuration to reuse under it. To insert the configuration somewhere else in the file, you use YAML anchors. Anchors allow you to create an alias for the configuration that effectively inserts the configuration fragment wherever you reference the anchor. The example on the right shows how an extension field called x-logging is used for configuring logging in two services. The anchor is indicated with an ampersand and is named default-logging. In the service definitions, the asterisk precedes the anchor name to indicate that an anchor is being used as the logging value. The extension field mapping including both options and driver are inserted at the proper indentation level where the default-logging anchor is referenced with an asterisk. The example illustrates how extension fields are useful for removing configuration clones.\par
\par
\par
Recap\par
This lesson began with a crash course in YAML. You learned about the string, integer, null, and Boolean data types. You also learned about the two collections in YAML: mappings, and sequences. This was just enough YAML to understand and write Compose files.\par
Next you understood the anatomy of a Compose file. The configuration in compose files falls under the top-level mapping keys of version, services, volumes, and networks. The configuration for services, volumes, and networks are similar to parameters you pass for docker run, volume create, and network create commands, but formatted in YAML syntax.\par
We finished the lesson by covering a couple special topics in Compose files. Variable substitutions allow you to generalize a Compose file using environment variables. Extension fields let you reuse configuration fragments to cut down on clones.\par
Up until now, you\rquote ve only seen how to declare what\rquote s in your multi-container applications. In the next lesson, you will see how to use the docker-compose command-line interface to run and manage the applications. When you are ready to learn how to start running your Compose file applications, continue on to the next lesson.\par
{{\field{\*\fldinst{HYPERLINK https://docs.docker.com/compose/compose-file }}{\fldrslt{https://docs.docker.com/compose/compose-file\ul0\cf0}}}}\f0\fs22\par
\par
\par
\b\fs32 Features and Commands of Compose Command-Line Interface\b0\fs22\par
\par
In this lesson, we\rquote ll see how to use the Docker Compose command-line interface to turn the multi-container applications described in Compose files into actual running environments in Docker.\par
\par
Agenda\par
I\rquote ll start by reviewing some of the high-level features of the Compose CLI.\par
Next, I will go through some of the installation options available for different platforms.\par
Lastly, I\rquote ll finish the lesson by looking at how to use the docker-compose CLI by the reviewing common commands and parameters\par
\par
\par
Features\par
One of the features of the Compose CLI that I want to highlight is its ability to run multiple isolated environments on a single host. Some scenarios where this is extremely useful is on a continuous integration server where you need to run automated tests for each build version. The ability of Compose to run multiple isolated environments means you don\rquote t have to sequentially iterate through each version. A development scenario where this comes in handy is when you may need to create multiple copies of an environment for different feature branches. You can use variable substitution in the Compose file to create the desired branch environment. We\rquote ll talk more about development scenarios in later lessons in this course.\par
The Compose CLI uses a parallel execution model to perform tasks for creating and deleting an application environment. Not everything can run in parallel due to dependencies and limitations in Docker, but when possible parallel execution is used to reduce the time it takes to manage applications.\par
Another useful feature to be aware of is the change detection capabilities of Compose. Every time you start a container for a service in Compose, the configuration is cached. If you later restart a Compose application, Compose will reuse any containers that haven\rquote t changed configuration. This is a bit like how layers are cached when building images from a Dockerfile. Just like with Dockerfiles, you can instruct Compose not to use the existing containers and instead force all containers to be rebuilt.\par
The last feature, using the term loosely, is that Docker Compose is an open source project on Github with an active community. You can report issues and make feature requests there. If you are familiar with the Python programming language, you can fork the project and modify the source to better suit your needs. Maybe even make a pull request to have your improvements included into the project.\par
\par
Installation\par
Before we get into using the Compose CLI, I want to say a few words about getting Compose installed on your system.\par
\par
For mac users, \par
Compose comes installed with the Docker for Mac application and Docker Toolbox for older systems.\par
\par
For Windows users,\par
If you obtained Docker through Docker for Windows, or Docker Toolbox\par
Compose came included with that.\par
If you are running the native Windows Docker Daemon, on Windows Server 2016 or Windows 10 with the Anniversary Update\par
You need to install Compose separately. You can choose the appropriate version of Compose and download an installer from the Compose Github releases page. For example, you could download version 1.17.0 to get the version of Compose I\rquote m using for this course.\par
\par
For Linux systems,\par
Docker Compose is included in many distribution repositories\par
For example, on CentOS or RedHat distributions you can use yum or dnf, and apt on Debian-based systems.\par
If Compose isn\rquote t available through the distribution\rquote s package repo or you want a specific version, \par
you can get Compose from the Github release page.\par
\par
Usage\par
All right! With that out of the way, we can look at how to use the Compose CLI. I\rquote ll show a couple slides to cover the Compose CLI basics and then hop over to my terminal to briefly illustrate using the Compose CLI.\par
docker-compose follows similar patterns to the docker CLI. You specify options to Compose, followed by a command, and add arguments for the command at the end. You can always use the --help argument to print a help page for any command.\par
\par
Compose will use the Docker Daemon running on the host by default.\par
You can connect to a Docker Daemon running on a remote host using the -H option. Along with that, you can secure the connection to the remote host using transport level security options. This requires the remote host to have been configured to use tls for the Docker Daemon.\par
For commands that reference a Compose file, the default Compose files that the CLI tries to find in the current directory are named docker-compose.yml or docker-compose.yaml.\par
It can be restrictive using only the default Compose file, so the -f option is provided to allow you to specify a path to any file that you want Compose to use as the Compose file for a command.\par
Each isolated application is associated with a project in Compose. The project is given a name and that name appears in resources that get created by Compose. For example, the names of networks and containers created by Compose begin the project name followed by the arbitrary name key declared in the Compose file.\par
The default project name is the name of the directory containing the Compose file.\par
You can assign a custom project name by using the -p option.\par
\par
Commands\par
As we have seen, Compose tries to make adoption easy for users already familiar with Docker. Most of the commands in the Compose CLI are familiar Docker commands that are generalized to work with multi-container applications.\par
This is the list of commands that exist in both Docker and Compose CLIs as of Compose version 1.17. As an example of how a command is generalized to multi-container applications, consider the stop command. In Docker, you use the stop command to stop one or more running containers passing the container names as arguments to the command. In Compose, the stop command will stop all containers declared in a Compose file, unless you provide the names of individual services to stop. Most commands generalize as you would expect. Some commands like config are not related to the Docker command. Config is useful for validating the YAML and configuration in a compose file. It\rquote s important to note that you can still use the docker CLI to work with resources created by Docker Compose. For example, containers created by Compose are listed by docker ps since they are created by the Docker daemon. Compose is just wrapping commands to generalize them to how you would expect them to work with multi-container applications.\par
After removing the commands that exist in Docker, there are currently only two non-deprecated commands that are unique to Compose and they are big ones.\par
\par
The first is up.\par
\par
The up command performs the actions required to instantiate the application described in a Compose file. It starts by creating default and named networks as applicable, and any named volumes.\par
It then takes the actions required to bring up service containers. This includes building images if required, then creating and starting containers, and finally attaching to the containers to aggregate output and error streams from the containers. When the command exits, the containers are all stopped. However, you can use the -d option to let the containers run in detached mode.\par
The up command is also responsible for performing change detection when you bring up an application that has already been brought up. It will recreate containers with changed configuration and join them to the appropriate networks. Any connections that were established with the original container are closed. There are several options for configuring how Compose does this if the default behavior isn\rquote t what you want.\par
The other command unique to Compose is down. Down is a partial opposite of up.\par
What I mean by partial opposite is that down will only remove containers, as well as any named and default networks by default.\par
It won\rquote t delete volumes or images that up created, unless you pass arguments instructing the command to do so. Up and down make it easy to perform integration tests in a continuous integration pipeline. You can simply wrap a test script between up and down to have the tests run in the isolated environment. Ok, with that, we\rquote ve covered enough of the Compose CLI to try it out and to use the help argument to find out more information when needed.\par
\par
@Terminal docker-compose\par
Here we are at my terminal. I want to demonstrate using the Compose CLI just to give a first look at it. We will cover more in-depth examples showing Compose in action in the remaining lessons in this course.\par
To start with, you can always get the usage information by appending --help on any command or docker-compose itself. I\rquote ll pipe it into more to page through the output. I won\rquote t read through the output since we\rquote ve discussed most of what is shown. The help output finishes with a list of all the available commands.\par
To get more information on the up command, I\rquote ll enter docker-compose up --help. I\rquote ll jump down to the options to see what\rquote s available for configuring the behavior of the up command. Just as an example, --no-deps can be used to prevent starting dependent services. This doesn\rquote t sound very useful when you first bring an application up, but if you later modify the configuration of one service, it can be useful to not restart the services that the one service depends on. As another example, adding the --remove-orphans option can clean up any services that are no longer declared in a compose file. This can happen if you delete a service outright from a Compose file or if you rename one.\par
To finish up, I\rquote ll demonstrate how to use docker-compose\rquote s config command to debug any YAML or configuration errors. You will also see how config shows you the effective configuration that is used by Compose after variable substitutions and extension field references.\par
If I switch over to VS Code, I have a Compose file open called 1-extension-fields.yml. It follows an example shown in the slides for using extension fields.\par
It\rquote s using version 3.4 which is good because that\rquote s the earliest version that supports extension fields. To see if everything is ok with the file, run the config command on it. At the terminal, I\rquote ll use the -f option to specify that file as the Compose file to use. So, Compose reports an error about services.cache.command contains true which is not valid. If I jump back to Code, it seems strange at first because there is no instances of true in the file. But remember that multiple words get mapped to true in YAML. Yes is one of them. Code has even changed the color to indicate that it isn\rquote t a string value. I\rquote ll add quotes around it to correct the error.\par
Running config again reveals a different error. The cache service doesn\rquote t set an image or build command so it can\rquote t be created. I\rquote ll set the image to redis, but I want to use variable substitution to set the tag, like so. Now when I run the config command again there are no errors and the effective configuration is displayed. Here you can see the default-logging YAML references have been replaced with the associated configuration under each services logging key. Compose reports a helpful warning at the top about the REDIS_VERSION variable not being set so an empty string is substituted. You can see that in the displayed configuration. That will need to be corrected. I\rquote ll export the variable\par
Export REDIS_VERSION=4.0.6\par
And the config command output confirms the variable is substituted into the configuration. I\rquote ll leave it at that for now. We\rquote ll see several more examples of Compose at the command-line in upcoming lessons.\par
\par
Recap\par
This lesson started by outlining some of the features of the Compose CLI including, how it can create multiple isolated environments on the same host. This makes it appealing for continuous integration, testing, and development scenarios. It also has built-in Compose file change detection support to only do what is required to bring the application to the desired state described in a Compose file.\par
We saw that the docker-compose CLI follows the same pattern as the docker CLI. Most of the commands in docker-compose are analogous to ones you find in docker.\par
There are however, two important commands that are unique to compose. Up does everything required to bring an application described in a Compose file up, and down brings an application down, removing containers and networks, but leaving images and volumes untouched by default.\par
In the next lesson, we\rquote ll go a step farther and bring up a web application with Compose using pre-built images from Docker Hub. When you are ready to see more of Compose in action, continue on with the next lesson.\par
{{\field{\*\fldinst{HYPERLINK https://github.com/docker/compose/releases }}{\fldrslt{https://github.com/docker/compose/releases\ul0\cf0}}}}\f0\fs22\par
\par
\par
\b\fs32 Deploying and Configuring a Web Application with Compose\b0\fs22\par
\par
Welcome back. This lesson will go through deploying a web application with Compose. This lesson is more applied than the previous ones. We\rquote ll spend most of our time at the command-line and making changes to a Compose file.\par
\par
Agenda\par
I\rquote ll start by briefly introducing the web application.\par
Then we\rquote ll get right into the demo.\par
\par
Wordpress\par
The web application that we\rquote ll use is WordPress. WordPress is a popular content management system or CMS. You can create websites and blogs in WordPress. WordPress is written in PHP and uses MySQL as a database. The images for WordPress and MySQL are maintained by Docker. Both images have over 10 million pull on Docker Hub. This scenario relates to operating the application. This is where images have been created and you pull them from a registry, possibly Docker Hub, or your own corporate image registry. The following lesson gets into developing applications with Compose. Now the stage is set, so let\rquote s hop over to Visual Studio Code to look at the Compose file I\rquote ve prepped for the application.\par
\par
@Terminal\par
Here is the Compose file, wordpress.yml. All of the contents just fit on the screen. Let\rquote s take a moment to go through it since it ties together a lot of what we\rquote ve seen in the course so far. There are two services, one for WordPress which is where the PHP application code exists and is served up by an apache web server, and one for the MySQL database. Both services use a specific tag on the image to have more control over the environment and to prevent unexpected changes from creeping in. Both services also have a restart key with the value of always. This is the same as the restart option for docker run. To make the application more production-worthy it\rquote s a good idea to have the container restarted automatically if it exits for some reason. You definitely want to persist data for a CMS, so the database service is using a named volume called db_data. This mounts into /var/lib/mysql in the container and is where MySQL stores its database files. Each service has a set of environment variables configured. The db service uses a mapping for its environment variables to create users and a database called wordpress. The wordpress service uses a sequence of strings to configure the database user and host with equal signs separating the variable names from their values. Both syntax styles are allowed and equivalent. One variable to highlight is WORDPRESS_DB_HOST in the wordpress service. It configures the database hostname. The value that is assigned is db on port 3306, the default port for MySQL. There are no named networks in this file. How can the wordpress service connect to the db? Both services will be added to the default network that Compose will create. The last bit of configuration, is the publishing of the wordpress port. The app will be available on port 8000 on the Docker host. The string is enclosed in quotes as a best practice although not strictly necessary in this case because the container port, 80, wouldn\rquote t mistakenly be interpreted as a base-60 number.\par
Switching over to my terminal, I\rquote m in the webapp directory which contains the wordpress.yml compose file. I\rquote m starting with a clean Docker environment. No containers, no volumes, and only the default Docker networks. I\rquote ll bring the wordpress application up now, using the -f option to specify a custom compose file. The db\rquote s mysql image gets pulled first followed by the wordpress image. I\rquote ll speed this up while the image layers get pulled. Now you can see in the output that the container for the db service is created first followed by the container for the wordpress service. This is guaranteed because the db is in the wordpress services depends_on sequence. The webapp at the beginning of the container name is the project name and it defaults to the current directory name which is webapp. The up command then attaches to the containers and aggregates their output. Compose uses color to distinguish between the output from different containers. You can see WordPress attempting to connect to the database and failing. Recall that depends_on doesn\rquote t wait until the database is ready, it only sequences the order containers are started in. Fortunately, WordPress follows the best practice of having the application handling failed connections and retrying until a connection is made. At this point, the db and wordpress services have finished initializing. I\rquote ll stop the docker-compose command with ctrl+z instead of exiting with ctrl+c so the containers don\rquote t get stopped. After clearing the screen, I\rquote ll list the containers with docker ps and confirm that the containers made by compose are like any others. Checking on the volumes, we can see the db_data named volume created by Compose. The unnamed volume comes from the WordPress image. It declares a volume for the WordPress web assets that get served up by the Apache web server in the /var/www/html directory. Next, we can see the default network Compose created in the networks list.\par
To verify the application is functioning correctly, I\rquote ll jump over to a browser and navigate to port 8000 on localhost where the WordPress service published its web server container port. The first time you use wordpress, you need to configure the language, a site title, and some user information. I\rquote ll set the title to Composing. The other details aren\rquote t important. With those details set, I can log in and see the admin dashboard. Up in the upper right corner I can navigate to the public site that\rquote s hosted by default. Here it is with the Composing title that I specified earlier. Everything is working as expected. We successfully ran a web application in Compose!\par
Let\rquote s see how the Compose change detection works. Say we decide to accept the risks of using the latest tag for the wordpress image. I\rquote ll change the tag, save the file, and go back to the terminal.\par
I\rquote ll repeat the up command except using the -d argument to run the containers in detached mode so the shell prompt will be returned to me after the command finishes. It starts by pulling down the latest version of the wordpress image. After that, it checks and sees that the db service container already running matches the configuration in the Compose file. There is no need to restart it. It then detects that the wordpress container doesn\rquote t match the configuration in the Compose file and recreates it using the updated configuration. You can change the behavior of up to suit your needs in different scenarios though. If you were uncertain if any other services had changed configuration and wanted to avoid recreating the db container at all costs, you can specify the --no-deps argument to up along with the service you want to bring up. In the output, notice that no check of the db service is made. If you want to recreate all containers even if their Compose configuration hasn\rquote t changed, you can pass the --force-recreate argument. The output indicates each container is being recreated now. To be certain, check the output of docker ps and see the containers have just been created. Now I will demonstrate bringing the application down with the down command. The output describes the steps Compose is taking, stopping containers, then removing containers, and lastly the default network Compose created. Docker ps -a verifies there is no trace of any service containers. I can bring the application back up again very quickly having previously downloaded the images. Now, if I load WordPress in the browser, what do you think I will see?\par
We don\rquote t see the first-time configuration page, we see the same composing site as before. That\rquote s because docker-compose down leaves the volumes by default.\par
You can change that default behavior though. Add --rmi all to remove all the images used in the Compose file, --volumes to delete the named volumes declared in the Compose file as well as well as any anonymous volumes attached to service containers, and --remove-orphans to delete any project containers that are no longer defined in the Compose file. This time you can see the removal of volumes and images in the output. There is still the old 4.9.0 wordpress image kicking around however. I\rquote ll use the image prune command to remove any images that are left over.\par
\par
Closing\par
That was pretty awesome! Managing the multi-container web app with Compose was painless. In the next lesson, we\rquote ll see how Compose works when we need to build the images using Dockerfiles.\par
\par
\par
\b\fs32 Using Compose Configurations and Commands to Build Images\b0\fs22\par
\par
Up until now, we have seen Compose working with images pulled from a Docker registry. Can you use Compose in development scenarios when the code isn\rquote t ready to be sealed in an image? How do you build images with Compose? These are the questions I\rquote ll answer in this lesson.\par
\par
Agenda\par
I\rquote ll begin by getting into the Compose file configuration and Compose commands needed for building images.\par
With that foundation in place, I\rquote ll finish the lesson with a demo that illustrates how to use Compose to build an image in a development scenario. Compose will bring the application up and your code changes will be reflected in the running container without needing to rebuild or stop the container. This provides a similar experience to developing on your local machine without Docker, but the server and all of the application dependencies are running inside a container.\par
\par
Building in Compose\par
When you build images in Compose, you make use of the same tried and true Dockerfiles that you use when building images with the docker build command. We won\rquote t get into the details of Dockerfiles in this lesson, but I\rquote ll quickly review one in the demo.\par
To instruct compose to build an image, add the build key in a service\rquote s configuration. There can be more than one service in a Compose file with a build mapping.\par
The Docker-compose up and docker-compose build commands can be used to build images. We\rquote ll take a closer at the build key and these commands in the next few slides.\par
\par
Build Key\par
If a service has a build key present, Docker Compose will build the image for the service. There are two forms of build configurations in a Compose file. The short form sets the build value to the path of the build context which is where the Dockerfile is located.\par
The longer form uses a nested mapping. The context is a required key and it has the same meaning as the context for the short form. The Dockerfile key is optional. If specified, the value is the name of the Dockerfile to use. If it isn\rquote t specified, Dockerfile will be used as the name for the file containing the image build instructions. Args are optional as well, and can be used to pass Arg values at build time. The Dockerfile should have corresponding ARG instructions.\par
The built image will be given a name that follows the pattern of Compose project name followed by the service name. If you want to use a different name, or want to specify a tag for the built image, beside the default latest tag, you can do so by using the image key. The image specified the image to pull from a Docker registry before, but if a build configuration is present for a service, the image is interpreted as the name of the built image.\par
Docker-compose up will build any image for services that don\rquote t have one already built. Subsequent up commands won\rquote t rebuild the image, unless you pass the --build option. This might not give enough control over built images, so there is another command for building.\par
Docker-compose build will build images or rebuild them if they already exist. Just like with the docker build command, there are a couple options to customize the behavior of docker-compose build. The --no-cache option will prevent using the layer cache causing all layers to be rebuilt. The --pull option will always attempt to pull a newer version of a base image described in the Dockerfile. That\rquote s all there is to building in Compose.\par
\par
Demo\par
Now, we\rquote ll get into a demo to illustrate building in Compose. The demo will use a NodeJS project that uses MongoDB for persistence. The image shows the app. It simply accumulates whatever messages users enter. The goal of the demo is to build an image with Compose that will allow on the fly updates as you modify the source code. No rebuilds and no stopping the containers. This gives the instant feedback that developers crave. Let\rquote s see how to do that.\par
Here in VS Code, I have a Dockerfile for the project open. It\rquote s called dev.dockerfile. I\rquote ll try to stay as language-agnostic as possible but the specific RUN instructions are specific to NodeJS development. At a high level, the instructions install the dependencies for developing and running the application. On line 5, nodemon is installed. nodemon is a tool that watches for changes to development files and automatically restarts the server to reflect the changes. On line 17, nodemon is set as the default command for running a container using the image. On lines 8 through 11, the src directory is created and set as the working directory. Then the application dependencies file, package.json, is added to the src directory in the image. The npm install command installs all of the dependencies in the src directory. Note that only the dependency file is added and not any source files. The image has everything the code needs to run but not the code itself. The development server port of 3000 is exposed on line 14. So how will this image be used to develop the code? The default command is expecting a file at /src/app/bin/www to start the server but it doesn\rquote t exist in the image. How will that work? The answer to both questions is by mounting a volume. Specifically, the source will be mounted at /src/app. The default command will then start a server using the code in your development environment. Let\rquote s take a look at the Compose file, that I\rquote ve called dev.docker-compose.yml.\par
There are two services, app and app-db, that are in the backend network. App publishes the port of 3000 so that the host can access the development server. There are a couple environment variables to configure NodeJS for development and to pass the hostname of the database. What\rquote s most important for this lesson is the build configuration. Because the dockerfile doesn\rquote t have the default name, the mapping syntax is required. The context is ., representing the directory of the Compose file which is also where the dockerfile is. The volumes key also plays an important role. The src directory on the host is mounted at /src/app where the development server expects to find it. Let\rquote s bring up the application using the Compose CLI. Thanks to the image configuration mapping, the built image will be named accumulator and will receive the default tag of latest.\par
I\rquote ll use the up command which builds the image since there is no prior image to use. I\rquote ll skip ahead to the build part. Each of the instructions in the Dockerfile are executed just like with docker build. I\rquote ll jump ahead to when the image is ready. There are some harmless warnings because some optional dependencies are specific to macs but the image is Linux. The output reports that the accumulator:latest tag is used. Compose also gives a helpful warning telling you to use the build command or pass the --build option to rebuild the image. Let\rquote s verify the app is up and running.\par
I\rquote ll point my browser to localhost on port 3000 and voila, the accumulator app is up and running. I\rquote ll enter some messages and refresh the page to ensure they are persisted in the database. Everything looks to be working.\par
I\rquote ll hop back to VS Code, and edit one of the views by adding a colon after Enter messages to accumulate, to confirm that the change gets updated in the browser. I\rquote ll save that change, and refresh the browser.\par
And there is the colon. That change was to a file that doesn\rquote t require restarting the server. To confirm that nodemon is correctly watching for changes, I\rquote ll modify a server-side JavaScript file.\par
I\rquote ll add some exclamation marks at the end of the development environment notice that appears in the upper right corner. Going back to the browser and refreshing\par
We see the changes reflected. No stopping the container and no build command required.\par
To show that nodemon detected the change, let\rquote s look at the app service\rquote s logs. There it is in green, restarting due to changes. That\rquote s pretty cool. You can use the development image to bundle up all the dependencies and all you need on your machine is the source files. You don\rquote t need the dependencies installed locally. By relying on the image for dependencies, you are a step closer to having parity between development and production because the production image would be using the same dependencies. The chance of the code working on your machine but not in production is greatly reduced. We\rquote ll look more at dev-prod parity in the next lesson.\par
I\rquote ll take the application down now. And if I bring it back up, do you think the test messages I entered into the application will still be there?\par
Let\rquote s refresh the page and see. In this case, the messages are gone. Recall that the db image isn\rquote t using a volume, so once the container is removed, everything is gone. That give an easy way to start fresh when developing this app, but you could easily add a volume if you wanted to persist the messages.\par
\par
Recap\par
This lesson illustrated how to build images and develop with Compose. The next lesson will further build upon what we\rquote ve learned in this Lesson to adapt Compose to multiple environments so you can share common configuration between development and production. When you are ready, continue on to the next lesson to see how it\rquote s done.\par
\par
\par
\b\fs32 How Compose Handles and Combines Multiple Files\b0\fs22\par
\par
We saw how to use Compose to build an image in a development scenario where the code is not ready to be sealed into the image. But what about once the code is ready? How can you use Compose to make the production image? Do you need to use two independent Compose files and Dockerfiles? This lesson will clear up these questions.\par
Agenda\par
I\rquote ll start with a discussion of how Compose handles multiple Compose files.\par
Then I\rquote ll mention a few considerations for using Compose for production environments.\par
I\rquote ll finish by reviewing the concepts we discuss in a demo. The demo extends the app from the previous lesson to use Compose for development and production environments.\par
\par
Multiple Compose Files\par
Although it\rquote s an option to maintain completely separate compose files for each environment you maintain,\par
\par
Compose has a useful feature that can combine Compose files.\par
\par
The semantics of combining Compose files is to treat the first file as a base configuration and each additional file overrides configuration specified in the base configuration. The overrides can add configuration that isn\rquote t present in the base configuration as well, not only strictly overriding existing values in the base configuration.\par
By default, Compose is set up to read two Compose files, the familiar docker-compose file, as well as an optional override file called docker-compose.override.yml.\par
The -f Compose option can be used multiple times to specify non-default override files. Each override file overriding the previous ones.\par
The Docker Compose config command is useful when writing and debugging multiple Compose files. It will display the effective Compose file after everything is combined.\par
The -H option of Compose allows you to manage the application on different Docker hosts, since the different environments are probably on different machines.\par
\par
Multiple Compose Files Example\par
Let\rquote s consider an example that uses Compose in two environments, one that is not intended for development, and another that is for development. The Dockerfile for the application is shown here. It\rquote s follows the non-development image pattern of copying all of the source code into the image, and installing the dependencies. Note that the source files are in the /src directory.\par
Here is the docker-compose.yml file, which plays the role of the base configuration in our example. Compose is instructed to build the web image using the current directory as the context, along with publishing a port on the host, and running a redis container. During the build the source files in the current directory get added to the image. The image can then create containers that don\rquote t have any dependency on source files outside of the container. This is what you want in a non-development scenario. Let\rquote s see how an override Compose file can extend the application to work in development scenarios. Can you guess?\par
On the right, I\rquote ve shown a development override Compose file. To use source files on your local machine instead of inside the image, you can use a volume. The example mounts the current directory at /src in the container. Because of the way that layering works in images, the files that are in the container are effectively overwritten by the volume. With this override, you can modify the source files on your local machine and see the changes reflected in a running container. It isn\rquote t always possible to use a common Dockerfile for each environment you intend to use the container. In that case, you can override the Dockerfile for each environment using the build\rquote s dockerfile configuration in each Compose file.\par
\par
Production Considerations\par
Moving to production environments is worthy of a course of its own. I will mention a few Compose file considerations for moving to a production environment, but know that there is more to it.\par
Remove any volumes for source code. You want the code to be frozen inside of a production image.\par
Consider using the always restart policy so services will automatically bring themselves back up if they exit.\par
Avoid host port conflicts that can prevent an application from coming up by letting Docker choose the host ports to use. You do this by only specifying the container port in the ports sequence.\par
Usually the runtime and the application have environment variables to configure production mode. This may reduce verbosity of logs and disable debug information.\par
The last one that I\rquote ll mention, is consider additional services that may be useful in production. For example, monitoring and log aggregation services. Now let\rquote s wrap up with a demo illustrating some of the concepts of using multiple compose files for development and production environments.\par
\par
Demo\par
I have a project open that is similar to the example in the previous lesson, except I\rquote ve modified it to use multiple Compose files. The development Dockerfile is the same as before. This is the file, dev.dockerfile, to refresh your memory. Because the application uses different ports and default commands for development and production, I\rquote ve written a separate production Dockerfile.\par
This is it here, prod.dockerfile. It doesn\rquote t install any development dependencies like nodemon and it copies all of the source files into the image, not just the dependency file. The exposed port has changed from 3000 to 8080 as well.\par
Now let\rquote s get to the main subject, the Compose files. This is the base Compose file, docker-compose.yml, that has configuration that is common to both environments. Then each environment has its own override file to add its own unique configuration. Alternatively, you could use the base configuration for the production environment, and have a single override file for development that not only adds but actually overrides settings in the base configuration. The configuration in this file is similar to the Compose file in the previous lesson\rquote s demo with the development specific configuration removed. One change is that the image has been given a registry URL. This allows you to later use docker-compose push to push the production image to a corporate registry, for example.\par
Looking at the development override Compose file now. This is the development specific configuration extracted from the single configuration in the previous lesson. When you tell Compose to use the base configuration plus this configuration as an override, it effectively reproduces the single development environment Compose file in the previous lesson. We\rquote ll actually see how they combine with the docker-compose config command in awhile.\par
And over to the final file we\rquote ll look at, the production override Compose file. I\rquote ve use the name prod but the image could and probably should be used for automated testing in a continuous integration system and/or staging before going into production. First, note the build configuration is set to use the prod dockerfile. We can also see several of the production considerations manifested in this override file. There is no volume for the app, both services are configured with the always restart policy, no specific host port is set to avoid port conflicts, and a production environment variable is set to configure the application for production. The last override is that the database is set to use a named volume to persist its data. In development it was considered optional, but we definitely want a volume in the production environment. Now let\rquote s take a look at how to use multiple Compose files on the command-line.\par
I\rquote ll focus on using the config command to show the effective configurations when you specify override files. I\rquote ll start by validating the configuration for the development environment. The command just adds an extra -f for the development override file. The output shows the combined configuration that Docker Compose will use. The output of config is more explicit than what was in the Compose files, in terms of using absolute paths and not having implicit null values. But we can clearly see that both configuration\rquote s options are there. For example, the base configuration\rquote s image and the development override\rquote s source code volume. I\rquote ll clear that and have one more go at it, this time specifying the production override file. And here we can see the effective configuration for the production environment. For example, the always restart policy on both services.\par
\par
Closing\par
In this Lesson, you saw how multiple Compose files and Docker Compose\rquote s override feature makes it easy to manage your multi-container applications in multiple environments. We also discussed some considerations for when one of those environments is production. When you are ready, continue on to the next lesson where we\rquote ll wrap up the course.\par
}
 